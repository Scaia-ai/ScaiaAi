{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Process-Emails\" data-toc-modified-id=\"Process-Emails-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Process Emails</a></span></li><li><span><a href=\"#Create-Bert-Embeddings-for-Emails\" data-toc-modified-id=\"Create-Bert-Embeddings-for-Emails-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Create Bert Embeddings for Emails</a></span></li><li><span><a href=\"#Nearest-Neighbors---Jaccard\" data-toc-modified-id=\"Nearest-Neighbors---Jaccard-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Nearest Neighbors - Jaccard</a></span></li><li><span><a href=\"#Nearest-Neighbors---Cosine\" data-toc-modified-id=\"Nearest-Neighbors---Cosine-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Nearest Neighbors - Cosine</a></span></li><li><span><a href=\"#Doc2Vec\" data-toc-modified-id=\"Doc2Vec-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Doc2Vec</a></span></li><li><span><a href=\"#Precision-&amp;-Recall\" data-toc-modified-id=\"Precision-&amp;-Recall-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Precision &amp; Recall</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from process_data import process_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_emails(data_folder = os.path.join(\"input_data\", \"results\", \"text\"), \n",
    "               email_text_file = os.path.join(\"input_data\", \"freed_texts.csv\"),\n",
    "               text_filter=\"EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \\\"ZL Technologies, Inc. (http://www.zlti.com)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Bert Embeddings for Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document_representations_bert import get_doc_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2019 02:25:35 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ubuntu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "11/21/2019 02:25:35 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at input_data/bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "11/21/2019 02:25:35 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file input_data/bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpjpsi7au_\n",
      "11/21/2019 02:25:39 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "11/21/2019 02:25:41 - INFO - root -   embedding chunk number: 0\n",
      "11/21/2019 02:29:05 - INFO - root -   embedding chunk number: 1\n",
      "11/21/2019 02:32:27 - INFO - root -   embedding chunk number: 2\n",
      "11/21/2019 02:35:52 - INFO - root -   embedding chunk number: 3\n",
      "11/21/2019 02:39:14 - INFO - root -   embedding chunk number: 4\n",
      "11/21/2019 02:42:38 - INFO - root -   embedding chunk number: 5\n",
      "11/21/2019 02:46:00 - INFO - root -   embedding chunk number: 6\n",
      "11/21/2019 02:48:07 - INFO - root -   Embeddings file successfully written to input_data/freed_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "get_doc_representations(input_email_text_file=os.path.join(\"input_data\", \"freed_texts.csv\"),\n",
    "                        output_embedding_file=os.path.join(\"input_data\", \"freed_embeddings.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors - Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nn_similarity import train_nn, test_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: input_data/freed_jaccard_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "train_nn(embeddings_file_path = os.path.join(\"input_data\", \"freed_embeddings.csv\"), \n",
    "         distance_type=\"jaccard\", \n",
    "         file_prefix=\"freed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 823\n",
      "1 / 823\n",
      "2 / 823\n",
      "3 / 823\n",
      "4 / 823\n",
      "5 / 823\n",
      "6 / 823\n",
      "7 / 823\n",
      "8 / 823\n",
      "9 / 823\n",
      "10 / 823\n",
      "11 / 823\n",
      "12 / 823\n",
      "13 / 823\n",
      "14 / 823\n",
      "15 / 823\n",
      "16 / 823\n",
      "17 / 823\n",
      "18 / 823\n",
      "19 / 823\n",
      "20 / 823\n",
      "21 / 823\n",
      "22 / 823\n",
      "23 / 823\n",
      "24 / 823\n",
      "25 / 823\n",
      "26 / 823\n",
      "27 / 823\n",
      "28 / 823\n",
      "29 / 823\n",
      "30 / 823\n",
      "31 / 823\n",
      "32 / 823\n",
      "33 / 823\n",
      "34 / 823\n",
      "35 / 823\n",
      "36 / 823\n",
      "37 / 823\n",
      "38 / 823\n",
      "39 / 823\n",
      "40 / 823\n",
      "41 / 823\n",
      "42 / 823\n",
      "43 / 823\n",
      "44 / 823\n",
      "45 / 823\n",
      "46 / 823\n",
      "47 / 823\n",
      "48 / 823\n",
      "49 / 823\n",
      "50 / 823\n",
      "51 / 823\n",
      "52 / 823\n",
      "53 / 823\n",
      "54 / 823\n",
      "55 / 823\n",
      "56 / 823\n",
      "57 / 823\n",
      "58 / 823\n",
      "59 / 823\n",
      "60 / 823\n",
      "61 / 823\n",
      "62 / 823\n",
      "63 / 823\n",
      "64 / 823\n",
      "65 / 823\n",
      "66 / 823\n",
      "67 / 823\n",
      "68 / 823\n",
      "69 / 823\n",
      "70 / 823\n",
      "71 / 823\n",
      "72 / 823\n",
      "73 / 823\n",
      "74 / 823\n",
      "75 / 823\n",
      "76 / 823\n",
      "77 / 823\n",
      "78 / 823\n",
      "79 / 823\n",
      "80 / 823\n",
      "81 / 823\n",
      "82 / 823\n",
      "83 / 823\n",
      "84 / 823\n",
      "85 / 823\n",
      "86 / 823\n",
      "87 / 823\n",
      "88 / 823\n",
      "89 / 823\n",
      "90 / 823\n",
      "91 / 823\n",
      "92 / 823\n",
      "93 / 823\n",
      "94 / 823\n",
      "95 / 823\n",
      "96 / 823\n",
      "97 / 823\n",
      "98 / 823\n",
      "99 / 823\n",
      "100 / 823\n",
      "101 / 823\n",
      "102 / 823\n",
      "103 / 823\n",
      "104 / 823\n",
      "105 / 823\n",
      "106 / 823\n",
      "107 / 823\n",
      "108 / 823\n",
      "109 / 823\n",
      "110 / 823\n",
      "111 / 823\n",
      "112 / 823\n",
      "113 / 823\n",
      "114 / 823\n",
      "115 / 823\n",
      "116 / 823\n",
      "117 / 823\n",
      "118 / 823\n",
      "119 / 823\n",
      "120 / 823\n",
      "121 / 823\n",
      "122 / 823\n",
      "123 / 823\n",
      "124 / 823\n",
      "125 / 823\n",
      "126 / 823\n",
      "127 / 823\n",
      "128 / 823\n",
      "129 / 823\n",
      "130 / 823\n",
      "131 / 823\n",
      "132 / 823\n",
      "133 / 823\n",
      "134 / 823\n",
      "135 / 823\n",
      "136 / 823\n",
      "137 / 823\n",
      "138 / 823\n",
      "139 / 823\n",
      "140 / 823\n",
      "141 / 823\n",
      "142 / 823\n",
      "143 / 823\n",
      "144 / 823\n",
      "145 / 823\n",
      "146 / 823\n",
      "147 / 823\n",
      "148 / 823\n",
      "149 / 823\n",
      "150 / 823\n",
      "151 / 823\n",
      "152 / 823\n",
      "153 / 823\n",
      "154 / 823\n",
      "155 / 823\n",
      "156 / 823\n",
      "157 / 823\n",
      "158 / 823\n",
      "159 / 823\n",
      "160 / 823\n",
      "161 / 823\n",
      "162 / 823\n",
      "163 / 823\n",
      "164 / 823\n",
      "165 / 823\n",
      "166 / 823\n",
      "167 / 823\n",
      "168 / 823\n",
      "169 / 823\n",
      "170 / 823\n",
      "171 / 823\n",
      "172 / 823\n",
      "173 / 823\n",
      "174 / 823\n",
      "175 / 823\n",
      "176 / 823\n",
      "177 / 823\n",
      "178 / 823\n",
      "179 / 823\n",
      "180 / 823\n",
      "181 / 823\n",
      "182 / 823\n",
      "183 / 823\n",
      "184 / 823\n",
      "185 / 823\n",
      "186 / 823\n",
      "187 / 823\n",
      "188 / 823\n",
      "189 / 823\n",
      "190 / 823\n",
      "191 / 823\n",
      "192 / 823\n",
      "193 / 823\n",
      "194 / 823\n",
      "195 / 823\n",
      "196 / 823\n",
      "197 / 823\n",
      "198 / 823\n",
      "199 / 823\n",
      "200 / 823\n",
      "201 / 823\n",
      "202 / 823\n",
      "203 / 823\n",
      "204 / 823\n",
      "205 / 823\n",
      "206 / 823\n",
      "207 / 823\n",
      "208 / 823\n",
      "209 / 823\n",
      "210 / 823\n",
      "211 / 823\n",
      "212 / 823\n",
      "213 / 823\n",
      "214 / 823\n",
      "215 / 823\n",
      "216 / 823\n",
      "217 / 823\n",
      "218 / 823\n",
      "219 / 823\n",
      "220 / 823\n",
      "221 / 823\n",
      "222 / 823\n",
      "223 / 823\n",
      "224 / 823\n",
      "225 / 823\n",
      "226 / 823\n",
      "227 / 823\n",
      "228 / 823\n",
      "229 / 823\n",
      "230 / 823\n",
      "231 / 823\n",
      "232 / 823\n",
      "233 / 823\n",
      "234 / 823\n",
      "235 / 823\n",
      "236 / 823\n",
      "237 / 823\n",
      "238 / 823\n",
      "239 / 823\n",
      "240 / 823\n",
      "241 / 823\n",
      "242 / 823\n",
      "243 / 823\n",
      "244 / 823\n",
      "245 / 823\n",
      "246 / 823\n",
      "247 / 823\n",
      "248 / 823\n",
      "249 / 823\n",
      "250 / 823\n",
      "251 / 823\n",
      "252 / 823\n",
      "253 / 823\n",
      "254 / 823\n",
      "255 / 823\n",
      "256 / 823\n",
      "257 / 823\n",
      "258 / 823\n",
      "259 / 823\n",
      "260 / 823\n",
      "261 / 823\n",
      "262 / 823\n",
      "263 / 823\n",
      "264 / 823\n",
      "265 / 823\n",
      "266 / 823\n",
      "267 / 823\n",
      "268 / 823\n",
      "269 / 823\n",
      "270 / 823\n",
      "271 / 823\n",
      "272 / 823\n",
      "273 / 823\n",
      "274 / 823\n",
      "275 / 823\n",
      "276 / 823\n",
      "277 / 823\n",
      "278 / 823\n",
      "279 / 823\n",
      "280 / 823\n",
      "281 / 823\n",
      "282 / 823\n",
      "283 / 823\n",
      "284 / 823\n",
      "285 / 823\n",
      "286 / 823\n",
      "287 / 823\n",
      "288 / 823\n",
      "289 / 823\n",
      "290 / 823\n",
      "291 / 823\n",
      "292 / 823\n",
      "293 / 823\n",
      "294 / 823\n",
      "295 / 823\n",
      "296 / 823\n",
      "297 / 823\n",
      "298 / 823\n",
      "299 / 823\n",
      "300 / 823\n",
      "301 / 823\n",
      "302 / 823\n",
      "303 / 823\n",
      "304 / 823\n",
      "305 / 823\n",
      "306 / 823\n",
      "307 / 823\n",
      "308 / 823\n",
      "309 / 823\n",
      "310 / 823\n",
      "311 / 823\n",
      "312 / 823\n",
      "313 / 823\n",
      "314 / 823\n",
      "315 / 823\n",
      "316 / 823\n",
      "317 / 823\n",
      "318 / 823\n",
      "319 / 823\n",
      "320 / 823\n",
      "321 / 823\n",
      "322 / 823\n",
      "323 / 823\n",
      "324 / 823\n",
      "325 / 823\n",
      "326 / 823\n",
      "327 / 823\n",
      "328 / 823\n",
      "329 / 823\n",
      "330 / 823\n",
      "331 / 823\n",
      "332 / 823\n",
      "333 / 823\n",
      "334 / 823\n",
      "335 / 823\n",
      "336 / 823\n",
      "337 / 823\n",
      "338 / 823\n",
      "339 / 823\n",
      "340 / 823\n",
      "341 / 823\n",
      "342 / 823\n",
      "343 / 823\n",
      "344 / 823\n",
      "345 / 823\n",
      "346 / 823\n",
      "347 / 823\n",
      "348 / 823\n",
      "349 / 823\n",
      "350 / 823\n",
      "351 / 823\n",
      "352 / 823\n",
      "353 / 823\n",
      "354 / 823\n",
      "355 / 823\n",
      "356 / 823\n",
      "357 / 823\n",
      "358 / 823\n",
      "359 / 823\n",
      "360 / 823\n",
      "361 / 823\n",
      "362 / 823\n",
      "363 / 823\n",
      "364 / 823\n",
      "365 / 823\n",
      "366 / 823\n",
      "367 / 823\n",
      "368 / 823\n",
      "369 / 823\n",
      "370 / 823\n",
      "371 / 823\n",
      "372 / 823\n",
      "373 / 823\n",
      "374 / 823\n",
      "375 / 823\n",
      "376 / 823\n",
      "377 / 823\n",
      "378 / 823\n",
      "379 / 823\n",
      "380 / 823\n",
      "381 / 823\n",
      "382 / 823\n",
      "383 / 823\n",
      "384 / 823\n",
      "385 / 823\n",
      "386 / 823\n",
      "387 / 823\n",
      "388 / 823\n",
      "389 / 823\n",
      "390 / 823\n",
      "391 / 823\n",
      "392 / 823\n",
      "393 / 823\n",
      "394 / 823\n",
      "395 / 823\n",
      "396 / 823\n",
      "397 / 823\n",
      "398 / 823\n",
      "399 / 823\n",
      "400 / 823\n",
      "401 / 823\n",
      "402 / 823\n",
      "403 / 823\n",
      "404 / 823\n",
      "405 / 823\n",
      "406 / 823\n",
      "407 / 823\n",
      "408 / 823\n",
      "409 / 823\n",
      "410 / 823\n",
      "411 / 823\n",
      "412 / 823\n",
      "413 / 823\n",
      "414 / 823\n",
      "415 / 823\n",
      "416 / 823\n",
      "417 / 823\n",
      "418 / 823\n",
      "419 / 823\n",
      "420 / 823\n",
      "421 / 823\n",
      "422 / 823\n",
      "423 / 823\n",
      "424 / 823\n",
      "425 / 823\n",
      "426 / 823\n",
      "427 / 823\n",
      "428 / 823\n",
      "429 / 823\n",
      "430 / 823\n",
      "431 / 823\n",
      "432 / 823\n",
      "433 / 823\n",
      "434 / 823\n",
      "435 / 823\n",
      "436 / 823\n",
      "437 / 823\n",
      "438 / 823\n",
      "439 / 823\n",
      "440 / 823\n",
      "441 / 823\n",
      "442 / 823\n",
      "443 / 823\n",
      "444 / 823\n",
      "445 / 823\n",
      "446 / 823\n",
      "447 / 823\n",
      "448 / 823\n",
      "449 / 823\n",
      "450 / 823\n",
      "451 / 823\n",
      "452 / 823\n",
      "453 / 823\n",
      "454 / 823\n",
      "455 / 823\n",
      "456 / 823\n",
      "457 / 823\n",
      "458 / 823\n",
      "459 / 823\n",
      "460 / 823\n",
      "461 / 823\n",
      "462 / 823\n",
      "463 / 823\n",
      "464 / 823\n",
      "465 / 823\n",
      "466 / 823\n",
      "467 / 823\n",
      "468 / 823\n",
      "469 / 823\n",
      "470 / 823\n",
      "471 / 823\n",
      "472 / 823\n",
      "473 / 823\n",
      "474 / 823\n",
      "475 / 823\n",
      "476 / 823\n",
      "477 / 823\n",
      "478 / 823\n",
      "479 / 823\n",
      "480 / 823\n",
      "481 / 823\n",
      "482 / 823\n",
      "483 / 823\n",
      "484 / 823\n",
      "485 / 823\n",
      "486 / 823\n",
      "487 / 823\n",
      "488 / 823\n",
      "489 / 823\n",
      "490 / 823\n",
      "491 / 823\n",
      "492 / 823\n",
      "493 / 823\n",
      "494 / 823\n",
      "495 / 823\n",
      "496 / 823\n",
      "497 / 823\n",
      "498 / 823\n",
      "499 / 823\n",
      "500 / 823\n",
      "501 / 823\n",
      "502 / 823\n",
      "503 / 823\n",
      "504 / 823\n",
      "505 / 823\n",
      "506 / 823\n",
      "507 / 823\n",
      "508 / 823\n",
      "509 / 823\n",
      "510 / 823\n",
      "511 / 823\n",
      "512 / 823\n",
      "513 / 823\n",
      "514 / 823\n",
      "515 / 823\n",
      "516 / 823\n",
      "517 / 823\n",
      "518 / 823\n",
      "519 / 823\n",
      "520 / 823\n",
      "521 / 823\n",
      "522 / 823\n",
      "523 / 823\n",
      "524 / 823\n",
      "525 / 823\n",
      "526 / 823\n",
      "527 / 823\n",
      "528 / 823\n",
      "529 / 823\n",
      "530 / 823\n",
      "531 / 823\n",
      "532 / 823\n",
      "533 / 823\n",
      "534 / 823\n",
      "535 / 823\n",
      "536 / 823\n",
      "537 / 823\n",
      "538 / 823\n",
      "539 / 823\n",
      "540 / 823\n",
      "541 / 823\n",
      "542 / 823\n",
      "543 / 823\n",
      "544 / 823\n",
      "545 / 823\n",
      "546 / 823\n",
      "547 / 823\n",
      "548 / 823\n",
      "549 / 823\n",
      "550 / 823\n",
      "551 / 823\n",
      "552 / 823\n",
      "553 / 823\n",
      "554 / 823\n",
      "555 / 823\n",
      "556 / 823\n",
      "557 / 823\n",
      "558 / 823\n",
      "559 / 823\n",
      "560 / 823\n",
      "561 / 823\n",
      "562 / 823\n",
      "563 / 823\n",
      "564 / 823\n",
      "565 / 823\n",
      "566 / 823\n",
      "567 / 823\n",
      "568 / 823\n",
      "569 / 823\n",
      "570 / 823\n",
      "571 / 823\n",
      "572 / 823\n",
      "573 / 823\n",
      "574 / 823\n",
      "575 / 823\n",
      "576 / 823\n",
      "577 / 823\n",
      "578 / 823\n",
      "579 / 823\n",
      "580 / 823\n",
      "581 / 823\n",
      "582 / 823\n",
      "583 / 823\n",
      "584 / 823\n",
      "585 / 823\n",
      "586 / 823\n",
      "587 / 823\n",
      "588 / 823\n",
      "589 / 823\n",
      "590 / 823\n",
      "591 / 823\n",
      "592 / 823\n",
      "593 / 823\n",
      "594 / 823\n",
      "595 / 823\n",
      "596 / 823\n",
      "597 / 823\n",
      "598 / 823\n",
      "599 / 823\n",
      "600 / 823\n",
      "601 / 823\n",
      "602 / 823\n",
      "603 / 823\n",
      "604 / 823\n",
      "605 / 823\n",
      "606 / 823\n",
      "607 / 823\n",
      "608 / 823\n",
      "609 / 823\n",
      "610 / 823\n",
      "611 / 823\n",
      "612 / 823\n",
      "613 / 823\n",
      "614 / 823\n",
      "615 / 823\n",
      "616 / 823\n",
      "617 / 823\n",
      "618 / 823\n",
      "619 / 823\n",
      "620 / 823\n",
      "621 / 823\n",
      "622 / 823\n",
      "623 / 823\n",
      "624 / 823\n",
      "625 / 823\n",
      "626 / 823\n",
      "627 / 823\n",
      "628 / 823\n",
      "629 / 823\n",
      "630 / 823\n",
      "631 / 823\n",
      "632 / 823\n",
      "633 / 823\n",
      "634 / 823\n",
      "635 / 823\n",
      "636 / 823\n",
      "637 / 823\n",
      "638 / 823\n",
      "639 / 823\n",
      "640 / 823\n",
      "641 / 823\n",
      "642 / 823\n",
      "643 / 823\n",
      "644 / 823\n",
      "645 / 823\n",
      "646 / 823\n",
      "647 / 823\n",
      "648 / 823\n",
      "649 / 823\n",
      "650 / 823\n",
      "651 / 823\n",
      "652 / 823\n",
      "653 / 823\n",
      "654 / 823\n",
      "655 / 823\n",
      "656 / 823\n",
      "657 / 823\n",
      "658 / 823\n",
      "659 / 823\n",
      "660 / 823\n",
      "661 / 823\n",
      "662 / 823\n",
      "663 / 823\n",
      "664 / 823\n",
      "665 / 823\n",
      "666 / 823\n",
      "667 / 823\n",
      "668 / 823\n",
      "669 / 823\n",
      "670 / 823\n",
      "671 / 823\n",
      "672 / 823\n",
      "673 / 823\n",
      "674 / 823\n",
      "675 / 823\n",
      "676 / 823\n",
      "677 / 823\n",
      "678 / 823\n",
      "679 / 823\n",
      "680 / 823\n",
      "681 / 823\n",
      "682 / 823\n",
      "683 / 823\n",
      "684 / 823\n",
      "685 / 823\n",
      "686 / 823\n",
      "687 / 823\n",
      "688 / 823\n",
      "689 / 823\n",
      "690 / 823\n",
      "691 / 823\n",
      "692 / 823\n",
      "693 / 823\n",
      "694 / 823\n",
      "695 / 823\n",
      "696 / 823\n",
      "697 / 823\n",
      "698 / 823\n",
      "699 / 823\n",
      "700 / 823\n",
      "701 / 823\n",
      "702 / 823\n",
      "703 / 823\n",
      "704 / 823\n",
      "705 / 823\n",
      "706 / 823\n",
      "707 / 823\n",
      "708 / 823\n",
      "709 / 823\n",
      "710 / 823\n",
      "711 / 823\n",
      "712 / 823\n",
      "713 / 823\n",
      "714 / 823\n",
      "715 / 823\n",
      "716 / 823\n",
      "717 / 823\n",
      "718 / 823\n",
      "719 / 823\n",
      "720 / 823\n",
      "721 / 823\n",
      "722 / 823\n",
      "723 / 823\n",
      "724 / 823\n",
      "725 / 823\n",
      "726 / 823\n",
      "727 / 823\n",
      "728 / 823\n",
      "729 / 823\n",
      "730 / 823\n",
      "731 / 823\n",
      "732 / 823\n",
      "733 / 823\n",
      "734 / 823\n",
      "735 / 823\n",
      "736 / 823\n",
      "737 / 823\n",
      "738 / 823\n",
      "739 / 823\n",
      "740 / 823\n",
      "741 / 823\n",
      "742 / 823\n",
      "743 / 823\n",
      "744 / 823\n",
      "745 / 823\n",
      "746 / 823\n",
      "747 / 823\n",
      "748 / 823\n",
      "749 / 823\n",
      "750 / 823\n",
      "751 / 823\n",
      "752 / 823\n",
      "753 / 823\n",
      "754 / 823\n",
      "755 / 823\n",
      "756 / 823\n",
      "757 / 823\n",
      "758 / 823\n",
      "759 / 823\n",
      "760 / 823\n",
      "761 / 823\n",
      "762 / 823\n",
      "763 / 823\n",
      "764 / 823\n",
      "765 / 823\n",
      "766 / 823\n",
      "767 / 823\n",
      "768 / 823\n",
      "769 / 823\n",
      "770 / 823\n",
      "771 / 823\n",
      "772 / 823\n",
      "773 / 823\n",
      "774 / 823\n",
      "775 / 823\n",
      "776 / 823\n",
      "777 / 823\n",
      "778 / 823\n",
      "779 / 823\n",
      "780 / 823\n",
      "781 / 823\n",
      "782 / 823\n",
      "783 / 823\n",
      "784 / 823\n",
      "785 / 823\n",
      "786 / 823\n",
      "787 / 823\n",
      "788 / 823\n",
      "789 / 823\n",
      "790 / 823\n",
      "791 / 823\n",
      "792 / 823\n",
      "793 / 823\n",
      "794 / 823\n",
      "795 / 823\n",
      "796 / 823\n",
      "797 / 823\n",
      "798 / 823\n",
      "799 / 823\n",
      "800 / 823\n",
      "801 / 823\n",
      "802 / 823\n",
      "803 / 823\n",
      "804 / 823\n",
      "805 / 823\n",
      "806 / 823\n",
      "807 / 823\n",
      "808 / 823\n",
      "809 / 823\n",
      "810 / 823\n",
      "811 / 823\n",
      "812 / 823\n",
      "813 / 823\n",
      "814 / 823\n",
      "815 / 823\n",
      "816 / 823\n",
      "817 / 823\n",
      "818 / 823\n",
      "819 / 823\n",
      "820 / 823\n",
      "821 / 823\n",
      "822 / 823\n",
      "Results saved to: output_data/freed_bert_testing_jaccard.csv\n"
     ]
    }
   ],
   "source": [
    "# test model on same train data\n",
    "test_nn(embeddings_file_path = os.path.join(\"input_data\", \"freed_embeddings.csv\"), \n",
    "        distance_type=\"jaccard\", \n",
    "        file_prefix=\"freed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors - Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nn_similarity import train_nn, test_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: input_data/freed_cosine_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "train_nn(embeddings_file_path = os.path.join(\"input_data\", \"freed_embeddings.csv\"), \n",
    "         distance_type=\"cosine\",\n",
    "         file_prefix=\"freed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 823\n",
      "1 / 823\n",
      "2 / 823\n",
      "3 / 823\n",
      "4 / 823\n",
      "5 / 823\n",
      "6 / 823\n",
      "7 / 823\n",
      "8 / 823\n",
      "9 / 823\n",
      "10 / 823\n",
      "11 / 823\n",
      "12 / 823\n",
      "13 / 823\n",
      "14 / 823\n",
      "15 / 823\n",
      "16 / 823\n",
      "17 / 823\n",
      "18 / 823\n",
      "19 / 823\n",
      "20 / 823\n",
      "21 / 823\n",
      "22 / 823\n",
      "23 / 823\n",
      "24 / 823\n",
      "25 / 823\n",
      "26 / 823\n",
      "27 / 823\n",
      "28 / 823\n",
      "29 / 823\n",
      "30 / 823\n",
      "31 / 823\n",
      "32 / 823\n",
      "33 / 823\n",
      "34 / 823\n",
      "35 / 823\n",
      "36 / 823\n",
      "37 / 823\n",
      "38 / 823\n",
      "39 / 823\n",
      "40 / 823\n",
      "41 / 823\n",
      "42 / 823\n",
      "43 / 823\n",
      "44 / 823\n",
      "45 / 823\n",
      "46 / 823\n",
      "47 / 823\n",
      "48 / 823\n",
      "49 / 823\n",
      "50 / 823\n",
      "51 / 823\n",
      "52 / 823\n",
      "53 / 823\n",
      "54 / 823\n",
      "55 / 823\n",
      "56 / 823\n",
      "57 / 823\n",
      "58 / 823\n",
      "59 / 823\n",
      "60 / 823\n",
      "61 / 823\n",
      "62 / 823\n",
      "63 / 823\n",
      "64 / 823\n",
      "65 / 823\n",
      "66 / 823\n",
      "67 / 823\n",
      "68 / 823\n",
      "69 / 823\n",
      "70 / 823\n",
      "71 / 823\n",
      "72 / 823\n",
      "73 / 823\n",
      "74 / 823\n",
      "75 / 823\n",
      "76 / 823\n",
      "77 / 823\n",
      "78 / 823\n",
      "79 / 823\n",
      "80 / 823\n",
      "81 / 823\n",
      "82 / 823\n",
      "83 / 823\n",
      "84 / 823\n",
      "85 / 823\n",
      "86 / 823\n",
      "87 / 823\n",
      "88 / 823\n",
      "89 / 823\n",
      "90 / 823\n",
      "91 / 823\n",
      "92 / 823\n",
      "93 / 823\n",
      "94 / 823\n",
      "95 / 823\n",
      "96 / 823\n",
      "97 / 823\n",
      "98 / 823\n",
      "99 / 823\n",
      "100 / 823\n",
      "101 / 823\n",
      "102 / 823\n",
      "103 / 823\n",
      "104 / 823\n",
      "105 / 823\n",
      "106 / 823\n",
      "107 / 823\n",
      "108 / 823\n",
      "109 / 823\n",
      "110 / 823\n",
      "111 / 823\n",
      "112 / 823\n",
      "113 / 823\n",
      "114 / 823\n",
      "115 / 823\n",
      "116 / 823\n",
      "117 / 823\n",
      "118 / 823\n",
      "119 / 823\n",
      "120 / 823\n",
      "121 / 823\n",
      "122 / 823\n",
      "123 / 823\n",
      "124 / 823\n",
      "125 / 823\n",
      "126 / 823\n",
      "127 / 823\n",
      "128 / 823\n",
      "129 / 823\n",
      "130 / 823\n",
      "131 / 823\n",
      "132 / 823\n",
      "133 / 823\n",
      "134 / 823\n",
      "135 / 823\n",
      "136 / 823\n",
      "137 / 823\n",
      "138 / 823\n",
      "139 / 823\n",
      "140 / 823\n",
      "141 / 823\n",
      "142 / 823\n",
      "143 / 823\n",
      "144 / 823\n",
      "145 / 823\n",
      "146 / 823\n",
      "147 / 823\n",
      "148 / 823\n",
      "149 / 823\n",
      "150 / 823\n",
      "151 / 823\n",
      "152 / 823\n",
      "153 / 823\n",
      "154 / 823\n",
      "155 / 823\n",
      "156 / 823\n",
      "157 / 823\n",
      "158 / 823\n",
      "159 / 823\n",
      "160 / 823\n",
      "161 / 823\n",
      "162 / 823\n",
      "163 / 823\n",
      "164 / 823\n",
      "165 / 823\n",
      "166 / 823\n",
      "167 / 823\n",
      "168 / 823\n",
      "169 / 823\n",
      "170 / 823\n",
      "171 / 823\n",
      "172 / 823\n",
      "173 / 823\n",
      "174 / 823\n",
      "175 / 823\n",
      "176 / 823\n",
      "177 / 823\n",
      "178 / 823\n",
      "179 / 823\n",
      "180 / 823\n",
      "181 / 823\n",
      "182 / 823\n",
      "183 / 823\n",
      "184 / 823\n",
      "185 / 823\n",
      "186 / 823\n",
      "187 / 823\n",
      "188 / 823\n",
      "189 / 823\n",
      "190 / 823\n",
      "191 / 823\n",
      "192 / 823\n",
      "193 / 823\n",
      "194 / 823\n",
      "195 / 823\n",
      "196 / 823\n",
      "197 / 823\n",
      "198 / 823\n",
      "199 / 823\n",
      "200 / 823\n",
      "201 / 823\n",
      "202 / 823\n",
      "203 / 823\n",
      "204 / 823\n",
      "205 / 823\n",
      "206 / 823\n",
      "207 / 823\n",
      "208 / 823\n",
      "209 / 823\n",
      "210 / 823\n",
      "211 / 823\n",
      "212 / 823\n",
      "213 / 823\n",
      "214 / 823\n",
      "215 / 823\n",
      "216 / 823\n",
      "217 / 823\n",
      "218 / 823\n",
      "219 / 823\n",
      "220 / 823\n",
      "221 / 823\n",
      "222 / 823\n",
      "223 / 823\n",
      "224 / 823\n",
      "225 / 823\n",
      "226 / 823\n",
      "227 / 823\n",
      "228 / 823\n",
      "229 / 823\n",
      "230 / 823\n",
      "231 / 823\n",
      "232 / 823\n",
      "233 / 823\n",
      "234 / 823\n",
      "235 / 823\n",
      "236 / 823\n",
      "237 / 823\n",
      "238 / 823\n",
      "239 / 823\n",
      "240 / 823\n",
      "241 / 823\n",
      "242 / 823\n",
      "243 / 823\n",
      "244 / 823\n",
      "245 / 823\n",
      "246 / 823\n",
      "247 / 823\n",
      "248 / 823\n",
      "249 / 823\n",
      "250 / 823\n",
      "251 / 823\n",
      "252 / 823\n",
      "253 / 823\n",
      "254 / 823\n",
      "255 / 823\n",
      "256 / 823\n",
      "257 / 823\n",
      "258 / 823\n",
      "259 / 823\n",
      "260 / 823\n",
      "261 / 823\n",
      "262 / 823\n",
      "263 / 823\n",
      "264 / 823\n",
      "265 / 823\n",
      "266 / 823\n",
      "267 / 823\n",
      "268 / 823\n",
      "269 / 823\n",
      "270 / 823\n",
      "271 / 823\n",
      "272 / 823\n",
      "273 / 823\n",
      "274 / 823\n",
      "275 / 823\n",
      "276 / 823\n",
      "277 / 823\n",
      "278 / 823\n",
      "279 / 823\n",
      "280 / 823\n",
      "281 / 823\n",
      "282 / 823\n",
      "283 / 823\n",
      "284 / 823\n",
      "285 / 823\n",
      "286 / 823\n",
      "287 / 823\n",
      "288 / 823\n",
      "289 / 823\n",
      "290 / 823\n",
      "291 / 823\n",
      "292 / 823\n",
      "293 / 823\n",
      "294 / 823\n",
      "295 / 823\n",
      "296 / 823\n",
      "297 / 823\n",
      "298 / 823\n",
      "299 / 823\n",
      "300 / 823\n",
      "301 / 823\n",
      "302 / 823\n",
      "303 / 823\n",
      "304 / 823\n",
      "305 / 823\n",
      "306 / 823\n",
      "307 / 823\n",
      "308 / 823\n",
      "309 / 823\n",
      "310 / 823\n",
      "311 / 823\n",
      "312 / 823\n",
      "313 / 823\n",
      "314 / 823\n",
      "315 / 823\n",
      "316 / 823\n",
      "317 / 823\n",
      "318 / 823\n",
      "319 / 823\n",
      "320 / 823\n",
      "321 / 823\n",
      "322 / 823\n",
      "323 / 823\n",
      "324 / 823\n",
      "325 / 823\n",
      "326 / 823\n",
      "327 / 823\n",
      "328 / 823\n",
      "329 / 823\n",
      "330 / 823\n",
      "331 / 823\n",
      "332 / 823\n",
      "333 / 823\n",
      "334 / 823\n",
      "335 / 823\n",
      "336 / 823\n",
      "337 / 823\n",
      "338 / 823\n",
      "339 / 823\n",
      "340 / 823\n",
      "341 / 823\n",
      "342 / 823\n",
      "343 / 823\n",
      "344 / 823\n",
      "345 / 823\n",
      "346 / 823\n",
      "347 / 823\n",
      "348 / 823\n",
      "349 / 823\n",
      "350 / 823\n",
      "351 / 823\n",
      "352 / 823\n",
      "353 / 823\n",
      "354 / 823\n",
      "355 / 823\n",
      "356 / 823\n",
      "357 / 823\n",
      "358 / 823\n",
      "359 / 823\n",
      "360 / 823\n",
      "361 / 823\n",
      "362 / 823\n",
      "363 / 823\n",
      "364 / 823\n",
      "365 / 823\n",
      "366 / 823\n",
      "367 / 823\n",
      "368 / 823\n",
      "369 / 823\n",
      "370 / 823\n",
      "371 / 823\n",
      "372 / 823\n",
      "373 / 823\n",
      "374 / 823\n",
      "375 / 823\n",
      "376 / 823\n",
      "377 / 823\n",
      "378 / 823\n",
      "379 / 823\n",
      "380 / 823\n",
      "381 / 823\n",
      "382 / 823\n",
      "383 / 823\n",
      "384 / 823\n",
      "385 / 823\n",
      "386 / 823\n",
      "387 / 823\n",
      "388 / 823\n",
      "389 / 823\n",
      "390 / 823\n",
      "391 / 823\n",
      "392 / 823\n",
      "393 / 823\n",
      "394 / 823\n",
      "395 / 823\n",
      "396 / 823\n",
      "397 / 823\n",
      "398 / 823\n",
      "399 / 823\n",
      "400 / 823\n",
      "401 / 823\n",
      "402 / 823\n",
      "403 / 823\n",
      "404 / 823\n",
      "405 / 823\n",
      "406 / 823\n",
      "407 / 823\n",
      "408 / 823\n",
      "409 / 823\n",
      "410 / 823\n",
      "411 / 823\n",
      "412 / 823\n",
      "413 / 823\n",
      "414 / 823\n",
      "415 / 823\n",
      "416 / 823\n",
      "417 / 823\n",
      "418 / 823\n",
      "419 / 823\n",
      "420 / 823\n",
      "421 / 823\n",
      "422 / 823\n",
      "423 / 823\n",
      "424 / 823\n",
      "425 / 823\n",
      "426 / 823\n",
      "427 / 823\n",
      "428 / 823\n",
      "429 / 823\n",
      "430 / 823\n",
      "431 / 823\n",
      "432 / 823\n",
      "433 / 823\n",
      "434 / 823\n",
      "435 / 823\n",
      "436 / 823\n",
      "437 / 823\n",
      "438 / 823\n",
      "439 / 823\n",
      "440 / 823\n",
      "441 / 823\n",
      "442 / 823\n",
      "443 / 823\n",
      "444 / 823\n",
      "445 / 823\n",
      "446 / 823\n",
      "447 / 823\n",
      "448 / 823\n",
      "449 / 823\n",
      "450 / 823\n",
      "451 / 823\n",
      "452 / 823\n",
      "453 / 823\n",
      "454 / 823\n",
      "455 / 823\n",
      "456 / 823\n",
      "457 / 823\n",
      "458 / 823\n",
      "459 / 823\n",
      "460 / 823\n",
      "461 / 823\n",
      "462 / 823\n",
      "463 / 823\n",
      "464 / 823\n",
      "465 / 823\n",
      "466 / 823\n",
      "467 / 823\n",
      "468 / 823\n",
      "469 / 823\n",
      "470 / 823\n",
      "471 / 823\n",
      "472 / 823\n",
      "473 / 823\n",
      "474 / 823\n",
      "475 / 823\n",
      "476 / 823\n",
      "477 / 823\n",
      "478 / 823\n",
      "479 / 823\n",
      "480 / 823\n",
      "481 / 823\n",
      "482 / 823\n",
      "483 / 823\n",
      "484 / 823\n",
      "485 / 823\n",
      "486 / 823\n",
      "487 / 823\n",
      "488 / 823\n",
      "489 / 823\n",
      "490 / 823\n",
      "491 / 823\n",
      "492 / 823\n",
      "493 / 823\n",
      "494 / 823\n",
      "495 / 823\n",
      "496 / 823\n",
      "497 / 823\n",
      "498 / 823\n",
      "499 / 823\n",
      "500 / 823\n",
      "501 / 823\n",
      "502 / 823\n",
      "503 / 823\n",
      "504 / 823\n",
      "505 / 823\n",
      "506 / 823\n",
      "507 / 823\n",
      "508 / 823\n",
      "509 / 823\n",
      "510 / 823\n",
      "511 / 823\n",
      "512 / 823\n",
      "513 / 823\n",
      "514 / 823\n",
      "515 / 823\n",
      "516 / 823\n",
      "517 / 823\n",
      "518 / 823\n",
      "519 / 823\n",
      "520 / 823\n",
      "521 / 823\n",
      "522 / 823\n",
      "523 / 823\n",
      "524 / 823\n",
      "525 / 823\n",
      "526 / 823\n",
      "527 / 823\n",
      "528 / 823\n",
      "529 / 823\n",
      "530 / 823\n",
      "531 / 823\n",
      "532 / 823\n",
      "533 / 823\n",
      "534 / 823\n",
      "535 / 823\n",
      "536 / 823\n",
      "537 / 823\n",
      "538 / 823\n",
      "539 / 823\n",
      "540 / 823\n",
      "541 / 823\n",
      "542 / 823\n",
      "543 / 823\n",
      "544 / 823\n",
      "545 / 823\n",
      "546 / 823\n",
      "547 / 823\n",
      "548 / 823\n",
      "549 / 823\n",
      "550 / 823\n",
      "551 / 823\n",
      "552 / 823\n",
      "553 / 823\n",
      "554 / 823\n",
      "555 / 823\n",
      "556 / 823\n",
      "557 / 823\n",
      "558 / 823\n",
      "559 / 823\n",
      "560 / 823\n",
      "561 / 823\n",
      "562 / 823\n",
      "563 / 823\n",
      "564 / 823\n",
      "565 / 823\n",
      "566 / 823\n",
      "567 / 823\n",
      "568 / 823\n",
      "569 / 823\n",
      "570 / 823\n",
      "571 / 823\n",
      "572 / 823\n",
      "573 / 823\n",
      "574 / 823\n",
      "575 / 823\n",
      "576 / 823\n",
      "577 / 823\n",
      "578 / 823\n",
      "579 / 823\n",
      "580 / 823\n",
      "581 / 823\n",
      "582 / 823\n",
      "583 / 823\n",
      "584 / 823\n",
      "585 / 823\n",
      "586 / 823\n",
      "587 / 823\n",
      "588 / 823\n",
      "589 / 823\n",
      "590 / 823\n",
      "591 / 823\n",
      "592 / 823\n",
      "593 / 823\n",
      "594 / 823\n",
      "595 / 823\n",
      "596 / 823\n",
      "597 / 823\n",
      "598 / 823\n",
      "599 / 823\n",
      "600 / 823\n",
      "601 / 823\n",
      "602 / 823\n",
      "603 / 823\n",
      "604 / 823\n",
      "605 / 823\n",
      "606 / 823\n",
      "607 / 823\n",
      "608 / 823\n",
      "609 / 823\n",
      "610 / 823\n",
      "611 / 823\n",
      "612 / 823\n",
      "613 / 823\n",
      "614 / 823\n",
      "615 / 823\n",
      "616 / 823\n",
      "617 / 823\n",
      "618 / 823\n",
      "619 / 823\n",
      "620 / 823\n",
      "621 / 823\n",
      "622 / 823\n",
      "623 / 823\n",
      "624 / 823\n",
      "625 / 823\n",
      "626 / 823\n",
      "627 / 823\n",
      "628 / 823\n",
      "629 / 823\n",
      "630 / 823\n",
      "631 / 823\n",
      "632 / 823\n",
      "633 / 823\n",
      "634 / 823\n",
      "635 / 823\n",
      "636 / 823\n",
      "637 / 823\n",
      "638 / 823\n",
      "639 / 823\n",
      "640 / 823\n",
      "641 / 823\n",
      "642 / 823\n",
      "643 / 823\n",
      "644 / 823\n",
      "645 / 823\n",
      "646 / 823\n",
      "647 / 823\n",
      "648 / 823\n",
      "649 / 823\n",
      "650 / 823\n",
      "651 / 823\n",
      "652 / 823\n",
      "653 / 823\n",
      "654 / 823\n",
      "655 / 823\n",
      "656 / 823\n",
      "657 / 823\n",
      "658 / 823\n",
      "659 / 823\n",
      "660 / 823\n",
      "661 / 823\n",
      "662 / 823\n",
      "663 / 823\n",
      "664 / 823\n",
      "665 / 823\n",
      "666 / 823\n",
      "667 / 823\n",
      "668 / 823\n",
      "669 / 823\n",
      "670 / 823\n",
      "671 / 823\n",
      "672 / 823\n",
      "673 / 823\n",
      "674 / 823\n",
      "675 / 823\n",
      "676 / 823\n",
      "677 / 823\n",
      "678 / 823\n",
      "679 / 823\n",
      "680 / 823\n",
      "681 / 823\n",
      "682 / 823\n",
      "683 / 823\n",
      "684 / 823\n",
      "685 / 823\n",
      "686 / 823\n",
      "687 / 823\n",
      "688 / 823\n",
      "689 / 823\n",
      "690 / 823\n",
      "691 / 823\n",
      "692 / 823\n",
      "693 / 823\n",
      "694 / 823\n",
      "695 / 823\n",
      "696 / 823\n",
      "697 / 823\n",
      "698 / 823\n",
      "699 / 823\n",
      "700 / 823\n",
      "701 / 823\n",
      "702 / 823\n",
      "703 / 823\n",
      "704 / 823\n",
      "705 / 823\n",
      "706 / 823\n",
      "707 / 823\n",
      "708 / 823\n",
      "709 / 823\n",
      "710 / 823\n",
      "711 / 823\n",
      "712 / 823\n",
      "713 / 823\n",
      "714 / 823\n",
      "715 / 823\n",
      "716 / 823\n",
      "717 / 823\n",
      "718 / 823\n",
      "719 / 823\n",
      "720 / 823\n",
      "721 / 823\n",
      "722 / 823\n",
      "723 / 823\n",
      "724 / 823\n",
      "725 / 823\n",
      "726 / 823\n",
      "727 / 823\n",
      "728 / 823\n",
      "729 / 823\n",
      "730 / 823\n",
      "731 / 823\n",
      "732 / 823\n",
      "733 / 823\n",
      "734 / 823\n",
      "735 / 823\n",
      "736 / 823\n",
      "737 / 823\n",
      "738 / 823\n",
      "739 / 823\n",
      "740 / 823\n",
      "741 / 823\n",
      "742 / 823\n",
      "743 / 823\n",
      "744 / 823\n",
      "745 / 823\n",
      "746 / 823\n",
      "747 / 823\n",
      "748 / 823\n",
      "749 / 823\n",
      "750 / 823\n",
      "751 / 823\n",
      "752 / 823\n",
      "753 / 823\n",
      "754 / 823\n",
      "755 / 823\n",
      "756 / 823\n",
      "757 / 823\n",
      "758 / 823\n",
      "759 / 823\n",
      "760 / 823\n",
      "761 / 823\n",
      "762 / 823\n",
      "763 / 823\n",
      "764 / 823\n",
      "765 / 823\n",
      "766 / 823\n",
      "767 / 823\n",
      "768 / 823\n",
      "769 / 823\n",
      "770 / 823\n",
      "771 / 823\n",
      "772 / 823\n",
      "773 / 823\n",
      "774 / 823\n",
      "775 / 823\n",
      "776 / 823\n",
      "777 / 823\n",
      "778 / 823\n",
      "779 / 823\n",
      "780 / 823\n",
      "781 / 823\n",
      "782 / 823\n",
      "783 / 823\n",
      "784 / 823\n",
      "785 / 823\n",
      "786 / 823\n",
      "787 / 823\n",
      "788 / 823\n",
      "789 / 823\n",
      "790 / 823\n",
      "791 / 823\n",
      "792 / 823\n",
      "793 / 823\n",
      "794 / 823\n",
      "795 / 823\n",
      "796 / 823\n",
      "797 / 823\n",
      "798 / 823\n",
      "799 / 823\n",
      "800 / 823\n",
      "801 / 823\n",
      "802 / 823\n",
      "803 / 823\n",
      "804 / 823\n",
      "805 / 823\n",
      "806 / 823\n",
      "807 / 823\n",
      "808 / 823\n",
      "809 / 823\n",
      "810 / 823\n",
      "811 / 823\n",
      "812 / 823\n",
      "813 / 823\n",
      "814 / 823\n",
      "815 / 823\n",
      "816 / 823\n",
      "817 / 823\n",
      "818 / 823\n",
      "819 / 823\n",
      "820 / 823\n",
      "821 / 823\n",
      "822 / 823\n",
      "Results saved to: output_data/freed_bert_testing_cosine.csv\n"
     ]
    }
   ],
   "source": [
    "# test model on same train data\n",
    "test_nn(embeddings_file_path = os.path.join(\"input_data\", \"freed_embeddings.csv\"), \n",
    "        distance_type=\"cosine\",\n",
    "        file_prefix=\"freed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2019 07:54:55 - INFO - gensim.summarization.textcleaner -   'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from doc2vec_similarity import train_doc2vec, test_doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2019 07:55:02 - WARNING - gensim.models.base_any2vec -   consider setting layer size to a multiple of 4 for greater performance\n",
      "11/21/2019 07:55:02 - INFO - gensim.models.doc2vec -   collecting all words and their counts\n",
      "11/21/2019 07:55:02 - INFO - gensim.models.doc2vec -   PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "11/21/2019 07:55:02 - INFO - gensim.models.doc2vec -   collected 20744 word types and 823 unique tags from a corpus of 823 examples and 640071 words\n",
      "11/21/2019 07:55:02 - INFO - gensim.models.word2vec -   Loading a fresh vocabulary\n",
      "11/21/2019 07:55:02 - INFO - gensim.models.word2vec -   effective_min_count=2 retains 15075 unique words (72% of original 20744, drops 5669)\n",
      "11/21/2019 07:55:02 - INFO - gensim.models.word2vec -   effective_min_count=2 leaves 634402 word corpus (99% of original 640071, drops 5669)\n",
      "11/21/2019 07:55:02 - INFO - gensim.models.word2vec -   deleting the raw counts dictionary of 20744 items\n",
      "11/21/2019 07:55:02 - INFO - gensim.models.word2vec -   sample=0.001 downsamples 52 most-common words\n",
      "11/21/2019 07:55:02 - INFO - gensim.models.word2vec -   downsampling leaves estimated 513783 word corpus (81.0% of prior 634402)\n",
      "11/21/2019 07:55:03 - INFO - gensim.models.base_any2vec -   estimated required memory for 15075 words and 50 dimensions: 13896700 bytes\n",
      "11/21/2019 07:55:03 - INFO - gensim.models.word2vec -   resetting layer weights\n",
      "11/21/2019 07:55:07 - INFO - gensim.models.base_any2vec -   training model with 3 workers on 15075 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "11/21/2019 07:55:08 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:08 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:08 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:08 - INFO - gensim.models.base_any2vec -   EPOCH - 1 : training on 640071 raw words (463276 effective words) took 0.5s, 960584 effective words/s\n",
      "11/21/2019 07:55:08 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:08 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:08 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:08 - INFO - gensim.models.base_any2vec -   EPOCH - 2 : training on 640071 raw words (463199 effective words) took 0.5s, 993537 effective words/s\n",
      "11/21/2019 07:55:08 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   EPOCH - 3 : training on 640071 raw words (462860 effective words) took 0.5s, 1014099 effective words/s\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   EPOCH - 4 : training on 640071 raw words (462873 effective words) took 0.5s, 981915 effective words/s\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:09 - INFO - gensim.models.base_any2vec -   EPOCH - 5 : training on 640071 raw words (463179 effective words) took 0.5s, 1006774 effective words/s\n",
      "11/21/2019 07:55:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:10 - INFO - gensim.models.base_any2vec -   EPOCH - 6 : training on 640071 raw words (462864 effective words) took 0.5s, 985425 effective words/s\n",
      "11/21/2019 07:55:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:10 - INFO - gensim.models.base_any2vec -   EPOCH - 7 : training on 640071 raw words (463317 effective words) took 0.5s, 986385 effective words/s\n",
      "11/21/2019 07:55:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:11 - INFO - gensim.models.base_any2vec -   EPOCH - 8 : training on 640071 raw words (462977 effective words) took 0.5s, 989967 effective words/s\n",
      "11/21/2019 07:55:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:11 - INFO - gensim.models.base_any2vec -   EPOCH - 9 : training on 640071 raw words (463268 effective words) took 0.5s, 1003119 effective words/s\n",
      "11/21/2019 07:55:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:12 - INFO - gensim.models.base_any2vec -   EPOCH - 10 : training on 640071 raw words (463011 effective words) took 0.5s, 953685 effective words/s\n",
      "11/21/2019 07:55:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:12 - INFO - gensim.models.base_any2vec -   EPOCH - 11 : training on 640071 raw words (463113 effective words) took 0.5s, 995839 effective words/s\n",
      "11/21/2019 07:55:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:13 - INFO - gensim.models.base_any2vec -   EPOCH - 12 : training on 640071 raw words (463290 effective words) took 0.5s, 1020471 effective words/s\n",
      "11/21/2019 07:55:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:13 - INFO - gensim.models.base_any2vec -   EPOCH - 13 : training on 640071 raw words (463013 effective words) took 0.5s, 977773 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2019 07:55:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:14 - INFO - gensim.models.base_any2vec -   EPOCH - 14 : training on 640071 raw words (462768 effective words) took 0.5s, 949021 effective words/s\n",
      "11/21/2019 07:55:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:14 - INFO - gensim.models.base_any2vec -   EPOCH - 15 : training on 640071 raw words (462869 effective words) took 0.5s, 974665 effective words/s\n",
      "11/21/2019 07:55:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:15 - INFO - gensim.models.base_any2vec -   EPOCH - 16 : training on 640071 raw words (463054 effective words) took 0.5s, 963986 effective words/s\n",
      "11/21/2019 07:55:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:15 - INFO - gensim.models.base_any2vec -   EPOCH - 17 : training on 640071 raw words (463117 effective words) took 0.5s, 978584 effective words/s\n",
      "11/21/2019 07:55:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:16 - INFO - gensim.models.base_any2vec -   EPOCH - 18 : training on 640071 raw words (463067 effective words) took 0.4s, 1032541 effective words/s\n",
      "11/21/2019 07:55:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:16 - INFO - gensim.models.base_any2vec -   EPOCH - 19 : training on 640071 raw words (463076 effective words) took 0.5s, 981070 effective words/s\n",
      "11/21/2019 07:55:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:17 - INFO - gensim.models.base_any2vec -   EPOCH - 20 : training on 640071 raw words (462894 effective words) took 0.5s, 987355 effective words/s\n",
      "11/21/2019 07:55:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:17 - INFO - gensim.models.base_any2vec -   EPOCH - 21 : training on 640071 raw words (462945 effective words) took 0.5s, 968731 effective words/s\n",
      "11/21/2019 07:55:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:18 - INFO - gensim.models.base_any2vec -   EPOCH - 22 : training on 640071 raw words (462813 effective words) took 0.5s, 1020689 effective words/s\n",
      "11/21/2019 07:55:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:18 - INFO - gensim.models.base_any2vec -   EPOCH - 23 : training on 640071 raw words (462972 effective words) took 0.5s, 1010283 effective words/s\n",
      "11/21/2019 07:55:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:18 - INFO - gensim.models.base_any2vec -   EPOCH - 24 : training on 640071 raw words (462775 effective words) took 0.5s, 974915 effective words/s\n",
      "11/21/2019 07:55:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:19 - INFO - gensim.models.base_any2vec -   EPOCH - 25 : training on 640071 raw words (463150 effective words) took 0.5s, 963311 effective words/s\n",
      "11/21/2019 07:55:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:19 - INFO - gensim.models.base_any2vec -   EPOCH - 26 : training on 640071 raw words (463087 effective words) took 0.5s, 980696 effective words/s\n",
      "11/21/2019 07:55:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:20 - INFO - gensim.models.base_any2vec -   EPOCH - 27 : training on 640071 raw words (462939 effective words) took 0.5s, 964430 effective words/s\n",
      "11/21/2019 07:55:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:20 - INFO - gensim.models.base_any2vec -   EPOCH - 28 : training on 640071 raw words (463141 effective words) took 0.5s, 956875 effective words/s\n",
      "11/21/2019 07:55:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:21 - INFO - gensim.models.base_any2vec -   EPOCH - 29 : training on 640071 raw words (463058 effective words) took 0.5s, 987110 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2019 07:55:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:21 - INFO - gensim.models.base_any2vec -   EPOCH - 30 : training on 640071 raw words (463205 effective words) took 0.5s, 992991 effective words/s\n",
      "11/21/2019 07:55:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:22 - INFO - gensim.models.base_any2vec -   EPOCH - 31 : training on 640071 raw words (462861 effective words) took 0.5s, 984902 effective words/s\n",
      "11/21/2019 07:55:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:22 - INFO - gensim.models.base_any2vec -   EPOCH - 32 : training on 640071 raw words (462858 effective words) took 0.5s, 1009691 effective words/s\n",
      "11/21/2019 07:55:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:23 - INFO - gensim.models.base_any2vec -   EPOCH - 33 : training on 640071 raw words (462878 effective words) took 0.5s, 1006509 effective words/s\n",
      "11/21/2019 07:55:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:23 - INFO - gensim.models.base_any2vec -   EPOCH - 34 : training on 640071 raw words (463148 effective words) took 0.5s, 1005220 effective words/s\n",
      "11/21/2019 07:55:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:24 - INFO - gensim.models.base_any2vec -   EPOCH - 35 : training on 640071 raw words (463076 effective words) took 0.5s, 1018358 effective words/s\n",
      "11/21/2019 07:55:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:24 - INFO - gensim.models.base_any2vec -   EPOCH - 36 : training on 640071 raw words (463065 effective words) took 0.5s, 1017940 effective words/s\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   EPOCH - 37 : training on 640071 raw words (463058 effective words) took 0.5s, 1025851 effective words/s\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   EPOCH - 38 : training on 640071 raw words (462863 effective words) took 0.4s, 1043821 effective words/s\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:25 - INFO - gensim.models.base_any2vec -   EPOCH - 39 : training on 640071 raw words (463211 effective words) took 0.5s, 1023127 effective words/s\n",
      "11/21/2019 07:55:26 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "11/21/2019 07:55:26 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "11/21/2019 07:55:26 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "11/21/2019 07:55:26 - INFO - gensim.models.base_any2vec -   EPOCH - 40 : training on 640071 raw words (462941 effective words) took 0.5s, 1020328 effective words/s\n",
      "11/21/2019 07:55:26 - INFO - gensim.models.base_any2vec -   training on a 25602840 raw words (18521129 effective words) took 18.8s, 983180 effective words/s\n",
      "11/21/2019 07:55:26 - INFO - gensim.utils -   saving Doc2Vec object under input_data/freed_doc2vec_model.bin, separately None\n",
      "11/21/2019 07:55:26 - INFO - gensim.utils -   saved input_data/freed_doc2vec_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: input_data/freed_doc2vec_model.bin\n"
     ]
    }
   ],
   "source": [
    "train_doc2vec(model_file_name = os.path.join(\"input_data\", \"freed_doc2vec_model.bin\"), \n",
    "              embeddings_file_path = os.path.join(\"input_data\", \"freed_embeddings.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2019 07:55:32 - INFO - gensim.utils -   loading Doc2Vec object from input_data/freed_doc2vec_model.bin\n",
      "11/21/2019 07:55:32 - INFO - gensim.utils -   loading vocabulary recursively from input_data/freed_doc2vec_model.bin.vocabulary.* with mmap=None\n",
      "11/21/2019 07:55:32 - INFO - gensim.utils -   loading trainables recursively from input_data/freed_doc2vec_model.bin.trainables.* with mmap=None\n",
      "11/21/2019 07:55:32 - INFO - gensim.utils -   loading wv recursively from input_data/freed_doc2vec_model.bin.wv.* with mmap=None\n",
      "11/21/2019 07:55:32 - INFO - gensim.utils -   loading docvecs recursively from input_data/freed_doc2vec_model.bin.docvecs.* with mmap=None\n",
      "11/21/2019 07:55:32 - INFO - gensim.utils -   loaded input_data/freed_doc2vec_model.bin\n",
      "11/21/2019 07:55:32 - INFO - gensim.models.keyedvectors -   precomputing L2-norms of doc weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: input_data/freed_doc2vec_model.bin\n"
     ]
    }
   ],
   "source": [
    "test_doc2vec(embeddings_file_path = os.path.join(\"input_data\", \"freed_embeddings.csv\"), \n",
    "             model_file_name = os.path.join(\"input_data\", \"freed_doc2vec_model.bin\"),\n",
    "             results_path = os.path.join(\"output_data\", \"freed_doc2vec_testing.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from precision_recall import p_r_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Name:  bert_jaccard\n",
      "Precision:  bert_jaccard 1.0\n",
      "Recall:  bert_jaccard 1.0\n",
      "F1 score:  bert_jaccard 1.0\n",
      "\n",
      "Model Name:  bert_cosine\n",
      "Precision:  bert_cosine 1.0\n",
      "Recall:  bert_cosine 1.0\n",
      "F1 score:  bert_cosine 1.0\n",
      "\n",
      "Model Name:  doc2vec\n",
      "Precision:  doc2vec 1.0\n",
      "Recall:  doc2vec 0.8092345078979344\n",
      "F1 score:  doc2vec 0.8945601074546675\n"
     ]
    }
   ],
   "source": [
    "p_r_f1_scores(jacc_results_path       = os.path.join(\"output_data\", \"freed_bert_testing_jaccard.csv\"),\n",
    "              cos_results_path        = os.path.join(\"output_data\", \"freed_bert_testing_cosine.csv\"),\n",
    "              doc2vec_results_path    = os.path.join(\"output_data\", \"freed_doc2vec_testing.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "274px",
    "width": "414px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
