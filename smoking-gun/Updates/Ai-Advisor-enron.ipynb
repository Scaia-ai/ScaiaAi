{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#To-download-Enron-Data-from-Web\" data-toc-modified-id=\"To-download-Enron-Data-from-Web-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>To download Enron Data from Web</a></span></li><li><span><a href=\"#Process-Emails\" data-toc-modified-id=\"Process-Emails-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Process Emails</a></span></li><li><span><a href=\"#Create-Bert-Embeddings-for-Emails\" data-toc-modified-id=\"Create-Bert-Embeddings-for-Emails-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create Bert Embeddings for Emails</a></span></li><li><span><a href=\"#Nearest-Neighbors---Manhattan\" data-toc-modified-id=\"Nearest-Neighbors---Manhattan-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Nearest Neighbors - Manhattan</a></span></li><li><span><a href=\"#Nearest-Neighbors---Cosine\" data-toc-modified-id=\"Nearest-Neighbors---Cosine-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Nearest Neighbors - Cosine</a></span></li><li><span><a href=\"#Doc2Vec\" data-toc-modified-id=\"Doc2Vec-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Doc2Vec</a></span></li><li><span><a href=\"#Precision-&amp;-Recall\" data-toc-modified-id=\"Precision-&amp;-Recall-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Precision &amp; Recall</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To download Enron Data from Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_enron import download_enron_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading File... https://s3.amazonaws.com/freeeed.org/enron/results/enron003.zip\n"
     ]
    }
   ],
   "source": [
    "download_enron_data(download_to_folder = os.path.join(\"input_data\", \"emails\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data import process_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_emails(data_folder = os.path.join(\"input_data\", \"emails\"), email_text_file = os.path.join(\"input_data\", \"enron_texts.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Bert Embeddings for Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/matthewdanielson/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from document_representations_bert import get_doc_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/20/2019 15:29:18 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/matthewdanielson/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "12/20/2019 15:29:18 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at input_data/bert/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "12/20/2019 15:29:18 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "12/20/2019 15:29:18 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at input_data/bert/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "12/20/2019 15:29:20 - INFO - root -   embedding chunk number: 0\n",
      "12/20/2019 15:31:37 - INFO - root -   embedding chunk number: 1\n",
      "12/20/2019 15:33:45 - INFO - root -   embedding chunk number: 2\n",
      "12/20/2019 15:35:55 - INFO - root -   embedding chunk number: 3\n",
      "12/20/2019 15:38:04 - INFO - root -   embedding chunk number: 4\n",
      "12/20/2019 15:40:14 - INFO - root -   embedding chunk number: 5\n",
      "12/20/2019 15:42:25 - INFO - root -   embedding chunk number: 6\n",
      "12/20/2019 15:44:36 - INFO - root -   embedding chunk number: 7\n",
      "12/20/2019 15:46:47 - INFO - root -   embedding chunk number: 8\n",
      "12/20/2019 15:48:58 - INFO - root -   embedding chunk number: 9\n",
      "12/20/2019 15:51:12 - INFO - root -   embedding chunk number: 10\n",
      "12/20/2019 15:53:20 - INFO - root -   embedding chunk number: 11\n",
      "12/20/2019 15:55:32 - INFO - root -   embedding chunk number: 12\n",
      "12/20/2019 15:57:11 - INFO - root -   Embeddings file successfully written to input_data/enron_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "get_doc_representations(input_email_text_file=os.path.join(\"input_data\", \"enron_texts.csv\"),\n",
    "                        output_embedding_file=os.path.join(\"input_data\", \"enron_embeddings.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopped above line after a while, as there are 1043264 records and 124 records per chunk, we would need to process 8414 times, and this would take more than a week to process, hence stopped. We still have good amount of data, i.e., 247*124 = 30628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors - Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_similarity import train_nn, test_nn, predict_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: input_data/enron_manhattan_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "train_nn(embeddings_file_path = os.path.join(\"input_data\", \"enron_embeddings.csv\"), \n",
    "         distance_type=\"manhattan\", \n",
    "         file_prefix=\"enron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1583\n",
      "1 / 1583\n",
      "2 / 1583\n",
      "3 / 1583\n",
      "4 / 1583\n",
      "5 / 1583\n",
      "6 / 1583\n",
      "7 / 1583\n",
      "8 / 1583\n",
      "9 / 1583\n",
      "10 / 1583\n",
      "11 / 1583\n",
      "12 / 1583\n",
      "13 / 1583\n",
      "14 / 1583\n",
      "15 / 1583\n",
      "16 / 1583\n",
      "17 / 1583\n",
      "18 / 1583\n",
      "19 / 1583\n",
      "20 / 1583\n",
      "21 / 1583\n",
      "22 / 1583\n",
      "23 / 1583\n",
      "24 / 1583\n",
      "25 / 1583\n",
      "26 / 1583\n",
      "27 / 1583\n",
      "28 / 1583\n",
      "29 / 1583\n",
      "30 / 1583\n",
      "31 / 1583\n",
      "32 / 1583\n",
      "33 / 1583\n",
      "34 / 1583\n",
      "35 / 1583\n",
      "36 / 1583\n",
      "37 / 1583\n",
      "38 / 1583\n",
      "39 / 1583\n",
      "40 / 1583\n",
      "41 / 1583\n",
      "42 / 1583\n",
      "43 / 1583\n",
      "44 / 1583\n",
      "45 / 1583\n",
      "46 / 1583\n",
      "47 / 1583\n",
      "48 / 1583\n",
      "49 / 1583\n",
      "50 / 1583\n",
      "51 / 1583\n",
      "52 / 1583\n",
      "53 / 1583\n",
      "54 / 1583\n",
      "55 / 1583\n",
      "56 / 1583\n",
      "57 / 1583\n",
      "58 / 1583\n",
      "59 / 1583\n",
      "60 / 1583\n",
      "61 / 1583\n",
      "62 / 1583\n",
      "63 / 1583\n",
      "64 / 1583\n",
      "65 / 1583\n",
      "66 / 1583\n",
      "67 / 1583\n",
      "68 / 1583\n",
      "69 / 1583\n",
      "70 / 1583\n",
      "71 / 1583\n",
      "72 / 1583\n",
      "73 / 1583\n",
      "74 / 1583\n",
      "75 / 1583\n",
      "76 / 1583\n",
      "77 / 1583\n",
      "78 / 1583\n",
      "79 / 1583\n",
      "80 / 1583\n",
      "81 / 1583\n",
      "82 / 1583\n",
      "83 / 1583\n",
      "84 / 1583\n",
      "85 / 1583\n",
      "86 / 1583\n",
      "87 / 1583\n",
      "88 / 1583\n",
      "89 / 1583\n",
      "90 / 1583\n",
      "91 / 1583\n",
      "92 / 1583\n",
      "93 / 1583\n",
      "94 / 1583\n",
      "95 / 1583\n",
      "96 / 1583\n",
      "97 / 1583\n",
      "98 / 1583\n",
      "99 / 1583\n",
      "100 / 1583\n",
      "101 / 1583\n",
      "102 / 1583\n",
      "103 / 1583\n",
      "104 / 1583\n",
      "105 / 1583\n",
      "106 / 1583\n",
      "107 / 1583\n",
      "108 / 1583\n",
      "109 / 1583\n",
      "110 / 1583\n",
      "111 / 1583\n",
      "112 / 1583\n",
      "113 / 1583\n",
      "114 / 1583\n",
      "115 / 1583\n",
      "116 / 1583\n",
      "117 / 1583\n",
      "118 / 1583\n",
      "119 / 1583\n",
      "120 / 1583\n",
      "121 / 1583\n",
      "122 / 1583\n",
      "123 / 1583\n",
      "124 / 1583\n",
      "125 / 1583\n",
      "126 / 1583\n",
      "127 / 1583\n",
      "128 / 1583\n",
      "129 / 1583\n",
      "130 / 1583\n",
      "131 / 1583\n",
      "132 / 1583\n",
      "133 / 1583\n",
      "134 / 1583\n",
      "135 / 1583\n",
      "136 / 1583\n",
      "137 / 1583\n",
      "138 / 1583\n",
      "139 / 1583\n",
      "140 / 1583\n",
      "141 / 1583\n",
      "142 / 1583\n",
      "143 / 1583\n",
      "144 / 1583\n",
      "145 / 1583\n",
      "146 / 1583\n",
      "147 / 1583\n",
      "148 / 1583\n",
      "149 / 1583\n",
      "150 / 1583\n",
      "151 / 1583\n",
      "152 / 1583\n",
      "153 / 1583\n",
      "154 / 1583\n",
      "155 / 1583\n",
      "156 / 1583\n",
      "157 / 1583\n",
      "158 / 1583\n",
      "159 / 1583\n",
      "160 / 1583\n",
      "161 / 1583\n",
      "162 / 1583\n",
      "163 / 1583\n",
      "164 / 1583\n",
      "165 / 1583\n",
      "166 / 1583\n",
      "167 / 1583\n",
      "168 / 1583\n",
      "169 / 1583\n",
      "170 / 1583\n",
      "171 / 1583\n",
      "172 / 1583\n",
      "173 / 1583\n",
      "174 / 1583\n",
      "175 / 1583\n",
      "176 / 1583\n",
      "177 / 1583\n",
      "178 / 1583\n",
      "179 / 1583\n",
      "180 / 1583\n",
      "181 / 1583\n",
      "182 / 1583\n",
      "183 / 1583\n",
      "184 / 1583\n",
      "185 / 1583\n",
      "186 / 1583\n",
      "187 / 1583\n",
      "188 / 1583\n",
      "189 / 1583\n",
      "190 / 1583\n",
      "191 / 1583\n",
      "192 / 1583\n",
      "193 / 1583\n",
      "194 / 1583\n",
      "195 / 1583\n",
      "196 / 1583\n",
      "197 / 1583\n",
      "198 / 1583\n",
      "199 / 1583\n",
      "200 / 1583\n",
      "201 / 1583\n",
      "202 / 1583\n",
      "203 / 1583\n",
      "204 / 1583\n",
      "205 / 1583\n",
      "206 / 1583\n",
      "207 / 1583\n",
      "208 / 1583\n",
      "209 / 1583\n",
      "210 / 1583\n",
      "211 / 1583\n",
      "212 / 1583\n",
      "213 / 1583\n",
      "214 / 1583\n",
      "215 / 1583\n",
      "216 / 1583\n",
      "217 / 1583\n",
      "218 / 1583\n",
      "219 / 1583\n",
      "220 / 1583\n",
      "221 / 1583\n",
      "222 / 1583\n",
      "223 / 1583\n",
      "224 / 1583\n",
      "225 / 1583\n",
      "226 / 1583\n",
      "227 / 1583\n",
      "228 / 1583\n",
      "229 / 1583\n",
      "230 / 1583\n",
      "231 / 1583\n",
      "232 / 1583\n",
      "233 / 1583\n",
      "234 / 1583\n",
      "235 / 1583\n",
      "236 / 1583\n",
      "237 / 1583\n",
      "238 / 1583\n",
      "239 / 1583\n",
      "240 / 1583\n",
      "241 / 1583\n",
      "242 / 1583\n",
      "243 / 1583\n",
      "244 / 1583\n",
      "245 / 1583\n",
      "246 / 1583\n",
      "247 / 1583\n",
      "248 / 1583\n",
      "249 / 1583\n",
      "250 / 1583\n",
      "251 / 1583\n",
      "252 / 1583\n",
      "253 / 1583\n",
      "254 / 1583\n",
      "255 / 1583\n",
      "256 / 1583\n",
      "257 / 1583\n",
      "258 / 1583\n",
      "259 / 1583\n",
      "260 / 1583\n",
      "261 / 1583\n",
      "262 / 1583\n",
      "263 / 1583\n",
      "264 / 1583\n",
      "265 / 1583\n",
      "266 / 1583\n",
      "267 / 1583\n",
      "268 / 1583\n",
      "269 / 1583\n",
      "270 / 1583\n",
      "271 / 1583\n",
      "272 / 1583\n",
      "273 / 1583\n",
      "274 / 1583\n",
      "275 / 1583\n",
      "276 / 1583\n",
      "277 / 1583\n",
      "278 / 1583\n",
      "279 / 1583\n",
      "280 / 1583\n",
      "281 / 1583\n",
      "282 / 1583\n",
      "283 / 1583\n",
      "284 / 1583\n",
      "285 / 1583\n",
      "286 / 1583\n",
      "287 / 1583\n",
      "288 / 1583\n",
      "289 / 1583\n",
      "290 / 1583\n",
      "291 / 1583\n",
      "292 / 1583\n",
      "293 / 1583\n",
      "294 / 1583\n",
      "295 / 1583\n",
      "296 / 1583\n",
      "297 / 1583\n",
      "298 / 1583\n",
      "299 / 1583\n",
      "300 / 1583\n",
      "301 / 1583\n",
      "302 / 1583\n",
      "303 / 1583\n",
      "304 / 1583\n",
      "305 / 1583\n",
      "306 / 1583\n",
      "307 / 1583\n",
      "308 / 1583\n",
      "309 / 1583\n",
      "310 / 1583\n",
      "311 / 1583\n",
      "312 / 1583\n",
      "313 / 1583\n",
      "314 / 1583\n",
      "315 / 1583\n",
      "316 / 1583\n",
      "317 / 1583\n",
      "318 / 1583\n",
      "319 / 1583\n",
      "320 / 1583\n",
      "321 / 1583\n",
      "322 / 1583\n",
      "323 / 1583\n",
      "324 / 1583\n",
      "325 / 1583\n",
      "326 / 1583\n",
      "327 / 1583\n",
      "328 / 1583\n",
      "329 / 1583\n",
      "330 / 1583\n",
      "331 / 1583\n",
      "332 / 1583\n",
      "333 / 1583\n",
      "334 / 1583\n",
      "335 / 1583\n",
      "336 / 1583\n",
      "337 / 1583\n",
      "338 / 1583\n",
      "339 / 1583\n",
      "340 / 1583\n",
      "341 / 1583\n",
      "342 / 1583\n",
      "343 / 1583\n",
      "344 / 1583\n",
      "345 / 1583\n",
      "346 / 1583\n",
      "347 / 1583\n",
      "348 / 1583\n",
      "349 / 1583\n",
      "350 / 1583\n",
      "351 / 1583\n",
      "352 / 1583\n",
      "353 / 1583\n",
      "354 / 1583\n",
      "355 / 1583\n",
      "356 / 1583\n",
      "357 / 1583\n",
      "358 / 1583\n",
      "359 / 1583\n",
      "360 / 1583\n",
      "361 / 1583\n",
      "362 / 1583\n",
      "363 / 1583\n",
      "364 / 1583\n",
      "365 / 1583\n",
      "366 / 1583\n",
      "367 / 1583\n",
      "368 / 1583\n",
      "369 / 1583\n",
      "370 / 1583\n",
      "371 / 1583\n",
      "372 / 1583\n",
      "373 / 1583\n",
      "374 / 1583\n",
      "375 / 1583\n",
      "376 / 1583\n",
      "377 / 1583\n",
      "378 / 1583\n",
      "379 / 1583\n",
      "380 / 1583\n",
      "381 / 1583\n",
      "382 / 1583\n",
      "383 / 1583\n",
      "384 / 1583\n",
      "385 / 1583\n",
      "386 / 1583\n",
      "387 / 1583\n",
      "388 / 1583\n",
      "389 / 1583\n",
      "390 / 1583\n",
      "391 / 1583\n",
      "392 / 1583\n",
      "393 / 1583\n",
      "394 / 1583\n",
      "395 / 1583\n",
      "396 / 1583\n",
      "397 / 1583\n",
      "398 / 1583\n",
      "399 / 1583\n",
      "400 / 1583\n",
      "401 / 1583\n",
      "402 / 1583\n",
      "403 / 1583\n",
      "404 / 1583\n",
      "405 / 1583\n",
      "406 / 1583\n",
      "407 / 1583\n",
      "408 / 1583\n",
      "409 / 1583\n",
      "410 / 1583\n",
      "411 / 1583\n",
      "412 / 1583\n",
      "413 / 1583\n",
      "414 / 1583\n",
      "415 / 1583\n",
      "416 / 1583\n",
      "417 / 1583\n",
      "418 / 1583\n",
      "419 / 1583\n",
      "420 / 1583\n",
      "421 / 1583\n",
      "422 / 1583\n",
      "423 / 1583\n",
      "424 / 1583\n",
      "425 / 1583\n",
      "426 / 1583\n",
      "427 / 1583\n",
      "428 / 1583\n",
      "429 / 1583\n",
      "430 / 1583\n",
      "431 / 1583\n",
      "432 / 1583\n",
      "433 / 1583\n",
      "434 / 1583\n",
      "435 / 1583\n",
      "436 / 1583\n",
      "437 / 1583\n",
      "438 / 1583\n",
      "439 / 1583\n",
      "440 / 1583\n",
      "441 / 1583\n",
      "442 / 1583\n",
      "443 / 1583\n",
      "444 / 1583\n",
      "445 / 1583\n",
      "446 / 1583\n",
      "447 / 1583\n",
      "448 / 1583\n",
      "449 / 1583\n",
      "450 / 1583\n",
      "451 / 1583\n",
      "452 / 1583\n",
      "453 / 1583\n",
      "454 / 1583\n",
      "455 / 1583\n",
      "456 / 1583\n",
      "457 / 1583\n",
      "458 / 1583\n",
      "459 / 1583\n",
      "460 / 1583\n",
      "461 / 1583\n",
      "462 / 1583\n",
      "463 / 1583\n",
      "464 / 1583\n",
      "465 / 1583\n",
      "466 / 1583\n",
      "467 / 1583\n",
      "468 / 1583\n",
      "469 / 1583\n",
      "470 / 1583\n",
      "471 / 1583\n",
      "472 / 1583\n",
      "473 / 1583\n",
      "474 / 1583\n",
      "475 / 1583\n",
      "476 / 1583\n",
      "477 / 1583\n",
      "478 / 1583\n",
      "479 / 1583\n",
      "480 / 1583\n",
      "481 / 1583\n",
      "482 / 1583\n",
      "483 / 1583\n",
      "484 / 1583\n",
      "485 / 1583\n",
      "486 / 1583\n",
      "487 / 1583\n",
      "488 / 1583\n",
      "489 / 1583\n",
      "490 / 1583\n",
      "491 / 1583\n",
      "492 / 1583\n",
      "493 / 1583\n",
      "494 / 1583\n",
      "495 / 1583\n",
      "496 / 1583\n",
      "497 / 1583\n",
      "498 / 1583\n",
      "499 / 1583\n",
      "500 / 1583\n",
      "501 / 1583\n",
      "502 / 1583\n",
      "503 / 1583\n",
      "504 / 1583\n",
      "505 / 1583\n",
      "506 / 1583\n",
      "507 / 1583\n",
      "508 / 1583\n",
      "509 / 1583\n",
      "510 / 1583\n",
      "511 / 1583\n",
      "512 / 1583\n",
      "513 / 1583\n",
      "514 / 1583\n",
      "515 / 1583\n",
      "516 / 1583\n",
      "517 / 1583\n",
      "518 / 1583\n",
      "519 / 1583\n",
      "520 / 1583\n",
      "521 / 1583\n",
      "522 / 1583\n",
      "523 / 1583\n",
      "524 / 1583\n",
      "525 / 1583\n",
      "526 / 1583\n",
      "527 / 1583\n",
      "528 / 1583\n",
      "529 / 1583\n",
      "530 / 1583\n",
      "531 / 1583\n",
      "532 / 1583\n",
      "533 / 1583\n",
      "534 / 1583\n",
      "535 / 1583\n",
      "536 / 1583\n",
      "537 / 1583\n",
      "538 / 1583\n",
      "539 / 1583\n",
      "540 / 1583\n",
      "541 / 1583\n",
      "542 / 1583\n",
      "543 / 1583\n",
      "544 / 1583\n",
      "545 / 1583\n",
      "546 / 1583\n",
      "547 / 1583\n",
      "548 / 1583\n",
      "549 / 1583\n",
      "550 / 1583\n",
      "551 / 1583\n",
      "552 / 1583\n",
      "553 / 1583\n",
      "554 / 1583\n",
      "555 / 1583\n",
      "556 / 1583\n",
      "557 / 1583\n",
      "558 / 1583\n",
      "559 / 1583\n",
      "560 / 1583\n",
      "561 / 1583\n",
      "562 / 1583\n",
      "563 / 1583\n",
      "564 / 1583\n",
      "565 / 1583\n",
      "566 / 1583\n",
      "567 / 1583\n",
      "568 / 1583\n",
      "569 / 1583\n",
      "570 / 1583\n",
      "571 / 1583\n",
      "572 / 1583\n",
      "573 / 1583\n",
      "574 / 1583\n",
      "575 / 1583\n",
      "576 / 1583\n",
      "577 / 1583\n",
      "578 / 1583\n",
      "579 / 1583\n",
      "580 / 1583\n",
      "581 / 1583\n",
      "582 / 1583\n",
      "583 / 1583\n",
      "584 / 1583\n",
      "585 / 1583\n",
      "586 / 1583\n",
      "587 / 1583\n",
      "588 / 1583\n",
      "589 / 1583\n",
      "590 / 1583\n",
      "591 / 1583\n",
      "592 / 1583\n",
      "593 / 1583\n",
      "594 / 1583\n",
      "595 / 1583\n",
      "596 / 1583\n",
      "597 / 1583\n",
      "598 / 1583\n",
      "599 / 1583\n",
      "600 / 1583\n",
      "601 / 1583\n",
      "602 / 1583\n",
      "603 / 1583\n",
      "604 / 1583\n",
      "605 / 1583\n",
      "606 / 1583\n",
      "607 / 1583\n",
      "608 / 1583\n",
      "609 / 1583\n",
      "610 / 1583\n",
      "611 / 1583\n",
      "612 / 1583\n",
      "613 / 1583\n",
      "614 / 1583\n",
      "615 / 1583\n",
      "616 / 1583\n",
      "617 / 1583\n",
      "618 / 1583\n",
      "619 / 1583\n",
      "620 / 1583\n",
      "621 / 1583\n",
      "622 / 1583\n",
      "623 / 1583\n",
      "624 / 1583\n",
      "625 / 1583\n",
      "626 / 1583\n",
      "627 / 1583\n",
      "628 / 1583\n",
      "629 / 1583\n",
      "630 / 1583\n",
      "631 / 1583\n",
      "632 / 1583\n",
      "633 / 1583\n",
      "634 / 1583\n",
      "635 / 1583\n",
      "636 / 1583\n",
      "637 / 1583\n",
      "638 / 1583\n",
      "639 / 1583\n",
      "640 / 1583\n",
      "641 / 1583\n",
      "642 / 1583\n",
      "643 / 1583\n",
      "644 / 1583\n",
      "645 / 1583\n",
      "646 / 1583\n",
      "647 / 1583\n",
      "648 / 1583\n",
      "649 / 1583\n",
      "650 / 1583\n",
      "651 / 1583\n",
      "652 / 1583\n",
      "653 / 1583\n",
      "654 / 1583\n",
      "655 / 1583\n",
      "656 / 1583\n",
      "657 / 1583\n",
      "658 / 1583\n",
      "659 / 1583\n",
      "660 / 1583\n",
      "661 / 1583\n",
      "662 / 1583\n",
      "663 / 1583\n",
      "664 / 1583\n",
      "665 / 1583\n",
      "666 / 1583\n",
      "667 / 1583\n",
      "668 / 1583\n",
      "669 / 1583\n",
      "670 / 1583\n",
      "671 / 1583\n",
      "672 / 1583\n",
      "673 / 1583\n",
      "674 / 1583\n",
      "675 / 1583\n",
      "676 / 1583\n",
      "677 / 1583\n",
      "678 / 1583\n",
      "679 / 1583\n",
      "680 / 1583\n",
      "681 / 1583\n",
      "682 / 1583\n",
      "683 / 1583\n",
      "684 / 1583\n",
      "685 / 1583\n",
      "686 / 1583\n",
      "687 / 1583\n",
      "688 / 1583\n",
      "689 / 1583\n",
      "690 / 1583\n",
      "691 / 1583\n",
      "692 / 1583\n",
      "693 / 1583\n",
      "694 / 1583\n",
      "695 / 1583\n",
      "696 / 1583\n",
      "697 / 1583\n",
      "698 / 1583\n",
      "699 / 1583\n",
      "700 / 1583\n",
      "701 / 1583\n",
      "702 / 1583\n",
      "703 / 1583\n",
      "704 / 1583\n",
      "705 / 1583\n",
      "706 / 1583\n",
      "707 / 1583\n",
      "708 / 1583\n",
      "709 / 1583\n",
      "710 / 1583\n",
      "711 / 1583\n",
      "712 / 1583\n",
      "713 / 1583\n",
      "714 / 1583\n",
      "715 / 1583\n",
      "716 / 1583\n",
      "717 / 1583\n",
      "718 / 1583\n",
      "719 / 1583\n",
      "720 / 1583\n",
      "721 / 1583\n",
      "722 / 1583\n",
      "723 / 1583\n",
      "724 / 1583\n",
      "725 / 1583\n",
      "726 / 1583\n",
      "727 / 1583\n",
      "728 / 1583\n",
      "729 / 1583\n",
      "730 / 1583\n",
      "731 / 1583\n",
      "732 / 1583\n",
      "733 / 1583\n",
      "734 / 1583\n",
      "735 / 1583\n",
      "736 / 1583\n",
      "737 / 1583\n",
      "738 / 1583\n",
      "739 / 1583\n",
      "740 / 1583\n",
      "741 / 1583\n",
      "742 / 1583\n",
      "743 / 1583\n",
      "744 / 1583\n",
      "745 / 1583\n",
      "746 / 1583\n",
      "747 / 1583\n",
      "748 / 1583\n",
      "749 / 1583\n",
      "750 / 1583\n",
      "751 / 1583\n",
      "752 / 1583\n",
      "753 / 1583\n",
      "754 / 1583\n",
      "755 / 1583\n",
      "756 / 1583\n",
      "757 / 1583\n",
      "758 / 1583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759 / 1583\n",
      "760 / 1583\n",
      "761 / 1583\n",
      "762 / 1583\n",
      "763 / 1583\n",
      "764 / 1583\n",
      "765 / 1583\n",
      "766 / 1583\n",
      "767 / 1583\n",
      "768 / 1583\n",
      "769 / 1583\n",
      "770 / 1583\n",
      "771 / 1583\n",
      "772 / 1583\n",
      "773 / 1583\n",
      "774 / 1583\n",
      "775 / 1583\n",
      "776 / 1583\n",
      "777 / 1583\n",
      "778 / 1583\n",
      "779 / 1583\n",
      "780 / 1583\n",
      "781 / 1583\n",
      "782 / 1583\n",
      "783 / 1583\n",
      "784 / 1583\n",
      "785 / 1583\n",
      "786 / 1583\n",
      "787 / 1583\n",
      "788 / 1583\n",
      "789 / 1583\n",
      "790 / 1583\n",
      "791 / 1583\n",
      "792 / 1583\n",
      "793 / 1583\n",
      "794 / 1583\n",
      "795 / 1583\n",
      "796 / 1583\n",
      "797 / 1583\n",
      "798 / 1583\n",
      "799 / 1583\n",
      "800 / 1583\n",
      "801 / 1583\n",
      "802 / 1583\n",
      "803 / 1583\n",
      "804 / 1583\n",
      "805 / 1583\n",
      "806 / 1583\n",
      "807 / 1583\n",
      "808 / 1583\n",
      "809 / 1583\n",
      "810 / 1583\n",
      "811 / 1583\n",
      "812 / 1583\n",
      "813 / 1583\n",
      "814 / 1583\n",
      "815 / 1583\n",
      "816 / 1583\n",
      "817 / 1583\n",
      "818 / 1583\n",
      "819 / 1583\n",
      "820 / 1583\n",
      "821 / 1583\n",
      "822 / 1583\n",
      "823 / 1583\n",
      "824 / 1583\n",
      "825 / 1583\n",
      "826 / 1583\n",
      "827 / 1583\n",
      "828 / 1583\n",
      "829 / 1583\n",
      "830 / 1583\n",
      "831 / 1583\n",
      "832 / 1583\n",
      "833 / 1583\n",
      "834 / 1583\n",
      "835 / 1583\n",
      "836 / 1583\n",
      "837 / 1583\n",
      "838 / 1583\n",
      "839 / 1583\n",
      "840 / 1583\n",
      "841 / 1583\n",
      "842 / 1583\n",
      "843 / 1583\n",
      "844 / 1583\n",
      "845 / 1583\n",
      "846 / 1583\n",
      "847 / 1583\n",
      "848 / 1583\n",
      "849 / 1583\n",
      "850 / 1583\n",
      "851 / 1583\n",
      "852 / 1583\n",
      "853 / 1583\n",
      "854 / 1583\n",
      "855 / 1583\n",
      "856 / 1583\n",
      "857 / 1583\n",
      "858 / 1583\n",
      "859 / 1583\n",
      "860 / 1583\n",
      "861 / 1583\n",
      "862 / 1583\n",
      "863 / 1583\n",
      "864 / 1583\n",
      "865 / 1583\n",
      "866 / 1583\n",
      "867 / 1583\n",
      "868 / 1583\n",
      "869 / 1583\n",
      "870 / 1583\n",
      "871 / 1583\n",
      "872 / 1583\n",
      "873 / 1583\n",
      "874 / 1583\n",
      "875 / 1583\n",
      "876 / 1583\n",
      "877 / 1583\n",
      "878 / 1583\n",
      "879 / 1583\n",
      "880 / 1583\n",
      "881 / 1583\n",
      "882 / 1583\n",
      "883 / 1583\n",
      "884 / 1583\n",
      "885 / 1583\n",
      "886 / 1583\n",
      "887 / 1583\n",
      "888 / 1583\n",
      "889 / 1583\n",
      "890 / 1583\n",
      "891 / 1583\n",
      "892 / 1583\n",
      "893 / 1583\n",
      "894 / 1583\n",
      "895 / 1583\n",
      "896 / 1583\n",
      "897 / 1583\n",
      "898 / 1583\n",
      "899 / 1583\n",
      "900 / 1583\n",
      "901 / 1583\n",
      "902 / 1583\n",
      "903 / 1583\n",
      "904 / 1583\n",
      "905 / 1583\n",
      "906 / 1583\n",
      "907 / 1583\n",
      "908 / 1583\n",
      "909 / 1583\n",
      "910 / 1583\n",
      "911 / 1583\n",
      "912 / 1583\n",
      "913 / 1583\n",
      "914 / 1583\n",
      "915 / 1583\n",
      "916 / 1583\n",
      "917 / 1583\n",
      "918 / 1583\n",
      "919 / 1583\n",
      "920 / 1583\n",
      "921 / 1583\n",
      "922 / 1583\n",
      "923 / 1583\n",
      "924 / 1583\n",
      "925 / 1583\n",
      "926 / 1583\n",
      "927 / 1583\n",
      "928 / 1583\n",
      "929 / 1583\n",
      "930 / 1583\n",
      "931 / 1583\n",
      "932 / 1583\n",
      "933 / 1583\n",
      "934 / 1583\n",
      "935 / 1583\n",
      "936 / 1583\n",
      "937 / 1583\n",
      "938 / 1583\n",
      "939 / 1583\n",
      "940 / 1583\n",
      "941 / 1583\n",
      "942 / 1583\n",
      "943 / 1583\n",
      "944 / 1583\n",
      "945 / 1583\n",
      "946 / 1583\n",
      "947 / 1583\n",
      "948 / 1583\n",
      "949 / 1583\n",
      "950 / 1583\n",
      "951 / 1583\n",
      "952 / 1583\n",
      "953 / 1583\n",
      "954 / 1583\n",
      "955 / 1583\n",
      "956 / 1583\n",
      "957 / 1583\n",
      "958 / 1583\n",
      "959 / 1583\n",
      "960 / 1583\n",
      "961 / 1583\n",
      "962 / 1583\n",
      "963 / 1583\n",
      "964 / 1583\n",
      "965 / 1583\n",
      "966 / 1583\n",
      "967 / 1583\n",
      "968 / 1583\n",
      "969 / 1583\n",
      "970 / 1583\n",
      "971 / 1583\n",
      "972 / 1583\n",
      "973 / 1583\n",
      "974 / 1583\n",
      "975 / 1583\n",
      "976 / 1583\n",
      "977 / 1583\n",
      "978 / 1583\n",
      "979 / 1583\n",
      "980 / 1583\n",
      "981 / 1583\n",
      "982 / 1583\n",
      "983 / 1583\n",
      "984 / 1583\n",
      "985 / 1583\n",
      "986 / 1583\n",
      "987 / 1583\n",
      "988 / 1583\n",
      "989 / 1583\n",
      "990 / 1583\n",
      "991 / 1583\n",
      "992 / 1583\n",
      "993 / 1583\n",
      "994 / 1583\n",
      "995 / 1583\n",
      "996 / 1583\n",
      "997 / 1583\n",
      "998 / 1583\n",
      "999 / 1583\n",
      "1000 / 1583\n",
      "1001 / 1583\n",
      "1002 / 1583\n",
      "1003 / 1583\n",
      "1004 / 1583\n",
      "1005 / 1583\n",
      "1006 / 1583\n",
      "1007 / 1583\n",
      "1008 / 1583\n",
      "1009 / 1583\n",
      "1010 / 1583\n",
      "1011 / 1583\n",
      "1012 / 1583\n",
      "1013 / 1583\n",
      "1014 / 1583\n",
      "1015 / 1583\n",
      "1016 / 1583\n",
      "1017 / 1583\n",
      "1018 / 1583\n",
      "1019 / 1583\n",
      "1020 / 1583\n",
      "1021 / 1583\n",
      "1022 / 1583\n",
      "1023 / 1583\n",
      "1024 / 1583\n",
      "1025 / 1583\n",
      "1026 / 1583\n",
      "1027 / 1583\n",
      "1028 / 1583\n",
      "1029 / 1583\n",
      "1030 / 1583\n",
      "1031 / 1583\n",
      "1032 / 1583\n",
      "1033 / 1583\n",
      "1034 / 1583\n",
      "1035 / 1583\n",
      "1036 / 1583\n",
      "1037 / 1583\n",
      "1038 / 1583\n",
      "1039 / 1583\n",
      "1040 / 1583\n",
      "1041 / 1583\n",
      "1042 / 1583\n",
      "1043 / 1583\n",
      "1044 / 1583\n",
      "1045 / 1583\n",
      "1046 / 1583\n",
      "1047 / 1583\n",
      "1048 / 1583\n",
      "1049 / 1583\n",
      "1050 / 1583\n",
      "1051 / 1583\n",
      "1052 / 1583\n",
      "1053 / 1583\n",
      "1054 / 1583\n",
      "1055 / 1583\n",
      "1056 / 1583\n",
      "1057 / 1583\n",
      "1058 / 1583\n",
      "1059 / 1583\n",
      "1060 / 1583\n",
      "1061 / 1583\n",
      "1062 / 1583\n",
      "1063 / 1583\n",
      "1064 / 1583\n",
      "1065 / 1583\n",
      "1066 / 1583\n",
      "1067 / 1583\n",
      "1068 / 1583\n",
      "1069 / 1583\n",
      "1070 / 1583\n",
      "1071 / 1583\n",
      "1072 / 1583\n",
      "1073 / 1583\n",
      "1074 / 1583\n",
      "1075 / 1583\n",
      "1076 / 1583\n",
      "1077 / 1583\n",
      "1078 / 1583\n",
      "1079 / 1583\n",
      "1080 / 1583\n",
      "1081 / 1583\n",
      "1082 / 1583\n",
      "1083 / 1583\n",
      "1084 / 1583\n",
      "1085 / 1583\n",
      "1086 / 1583\n",
      "1087 / 1583\n",
      "1088 / 1583\n",
      "1089 / 1583\n",
      "1090 / 1583\n",
      "1091 / 1583\n",
      "1092 / 1583\n",
      "1093 / 1583\n",
      "1094 / 1583\n",
      "1095 / 1583\n",
      "1096 / 1583\n",
      "1097 / 1583\n",
      "1098 / 1583\n",
      "1099 / 1583\n",
      "1100 / 1583\n",
      "1101 / 1583\n",
      "1102 / 1583\n",
      "1103 / 1583\n",
      "1104 / 1583\n",
      "1105 / 1583\n",
      "1106 / 1583\n",
      "1107 / 1583\n",
      "1108 / 1583\n",
      "1109 / 1583\n",
      "1110 / 1583\n",
      "1111 / 1583\n",
      "1112 / 1583\n",
      "1113 / 1583\n",
      "1114 / 1583\n",
      "1115 / 1583\n",
      "1116 / 1583\n",
      "1117 / 1583\n",
      "1118 / 1583\n",
      "1119 / 1583\n",
      "1120 / 1583\n",
      "1121 / 1583\n",
      "1122 / 1583\n",
      "1123 / 1583\n",
      "1124 / 1583\n",
      "1125 / 1583\n",
      "1126 / 1583\n",
      "1127 / 1583\n",
      "1128 / 1583\n",
      "1129 / 1583\n",
      "1130 / 1583\n",
      "1131 / 1583\n",
      "1132 / 1583\n",
      "1133 / 1583\n",
      "1134 / 1583\n",
      "1135 / 1583\n",
      "1136 / 1583\n",
      "1137 / 1583\n",
      "1138 / 1583\n",
      "1139 / 1583\n",
      "1140 / 1583\n",
      "1141 / 1583\n",
      "1142 / 1583\n",
      "1143 / 1583\n",
      "1144 / 1583\n",
      "1145 / 1583\n",
      "1146 / 1583\n",
      "1147 / 1583\n",
      "1148 / 1583\n",
      "1149 / 1583\n",
      "1150 / 1583\n",
      "1151 / 1583\n",
      "1152 / 1583\n",
      "1153 / 1583\n",
      "1154 / 1583\n",
      "1155 / 1583\n",
      "1156 / 1583\n",
      "1157 / 1583\n",
      "1158 / 1583\n",
      "1159 / 1583\n",
      "1160 / 1583\n",
      "1161 / 1583\n",
      "1162 / 1583\n",
      "1163 / 1583\n",
      "1164 / 1583\n",
      "1165 / 1583\n",
      "1166 / 1583\n",
      "1167 / 1583\n",
      "1168 / 1583\n",
      "1169 / 1583\n",
      "1170 / 1583\n",
      "1171 / 1583\n",
      "1172 / 1583\n",
      "1173 / 1583\n",
      "1174 / 1583\n",
      "1175 / 1583\n",
      "1176 / 1583\n",
      "1177 / 1583\n",
      "1178 / 1583\n",
      "1179 / 1583\n",
      "1180 / 1583\n",
      "1181 / 1583\n",
      "1182 / 1583\n",
      "1183 / 1583\n",
      "1184 / 1583\n",
      "1185 / 1583\n",
      "1186 / 1583\n",
      "1187 / 1583\n",
      "1188 / 1583\n",
      "1189 / 1583\n",
      "1190 / 1583\n",
      "1191 / 1583\n",
      "1192 / 1583\n",
      "1193 / 1583\n",
      "1194 / 1583\n",
      "1195 / 1583\n",
      "1196 / 1583\n",
      "1197 / 1583\n",
      "1198 / 1583\n",
      "1199 / 1583\n",
      "1200 / 1583\n",
      "1201 / 1583\n",
      "1202 / 1583\n",
      "1203 / 1583\n",
      "1204 / 1583\n",
      "1205 / 1583\n",
      "1206 / 1583\n",
      "1207 / 1583\n",
      "1208 / 1583\n",
      "1209 / 1583\n",
      "1210 / 1583\n",
      "1211 / 1583\n",
      "1212 / 1583\n",
      "1213 / 1583\n",
      "1214 / 1583\n",
      "1215 / 1583\n",
      "1216 / 1583\n",
      "1217 / 1583\n",
      "1218 / 1583\n",
      "1219 / 1583\n",
      "1220 / 1583\n",
      "1221 / 1583\n",
      "1222 / 1583\n",
      "1223 / 1583\n",
      "1224 / 1583\n",
      "1225 / 1583\n",
      "1226 / 1583\n",
      "1227 / 1583\n",
      "1228 / 1583\n",
      "1229 / 1583\n",
      "1230 / 1583\n",
      "1231 / 1583\n",
      "1232 / 1583\n",
      "1233 / 1583\n",
      "1234 / 1583\n",
      "1235 / 1583\n",
      "1236 / 1583\n",
      "1237 / 1583\n",
      "1238 / 1583\n",
      "1239 / 1583\n",
      "1240 / 1583\n",
      "1241 / 1583\n",
      "1242 / 1583\n",
      "1243 / 1583\n",
      "1244 / 1583\n",
      "1245 / 1583\n",
      "1246 / 1583\n",
      "1247 / 1583\n",
      "1248 / 1583\n",
      "1249 / 1583\n",
      "1250 / 1583\n",
      "1251 / 1583\n",
      "1252 / 1583\n",
      "1253 / 1583\n",
      "1254 / 1583\n",
      "1255 / 1583\n",
      "1256 / 1583\n",
      "1257 / 1583\n",
      "1258 / 1583\n",
      "1259 / 1583\n",
      "1260 / 1583\n",
      "1261 / 1583\n",
      "1262 / 1583\n",
      "1263 / 1583\n",
      "1264 / 1583\n",
      "1265 / 1583\n",
      "1266 / 1583\n",
      "1267 / 1583\n",
      "1268 / 1583\n",
      "1269 / 1583\n",
      "1270 / 1583\n",
      "1271 / 1583\n",
      "1272 / 1583\n",
      "1273 / 1583\n",
      "1274 / 1583\n",
      "1275 / 1583\n",
      "1276 / 1583\n",
      "1277 / 1583\n",
      "1278 / 1583\n",
      "1279 / 1583\n",
      "1280 / 1583\n",
      "1281 / 1583\n",
      "1282 / 1583\n",
      "1283 / 1583\n",
      "1284 / 1583\n",
      "1285 / 1583\n",
      "1286 / 1583\n",
      "1287 / 1583\n",
      "1288 / 1583\n",
      "1289 / 1583\n",
      "1290 / 1583\n",
      "1291 / 1583\n",
      "1292 / 1583\n",
      "1293 / 1583\n",
      "1294 / 1583\n",
      "1295 / 1583\n",
      "1296 / 1583\n",
      "1297 / 1583\n",
      "1298 / 1583\n",
      "1299 / 1583\n",
      "1300 / 1583\n",
      "1301 / 1583\n",
      "1302 / 1583\n",
      "1303 / 1583\n",
      "1304 / 1583\n",
      "1305 / 1583\n",
      "1306 / 1583\n",
      "1307 / 1583\n",
      "1308 / 1583\n",
      "1309 / 1583\n",
      "1310 / 1583\n",
      "1311 / 1583\n",
      "1312 / 1583\n",
      "1313 / 1583\n",
      "1314 / 1583\n",
      "1315 / 1583\n",
      "1316 / 1583\n",
      "1317 / 1583\n",
      "1318 / 1583\n",
      "1319 / 1583\n",
      "1320 / 1583\n",
      "1321 / 1583\n",
      "1322 / 1583\n",
      "1323 / 1583\n",
      "1324 / 1583\n",
      "1325 / 1583\n",
      "1326 / 1583\n",
      "1327 / 1583\n",
      "1328 / 1583\n",
      "1329 / 1583\n",
      "1330 / 1583\n",
      "1331 / 1583\n",
      "1332 / 1583\n",
      "1333 / 1583\n",
      "1334 / 1583\n",
      "1335 / 1583\n",
      "1336 / 1583\n",
      "1337 / 1583\n",
      "1338 / 1583\n",
      "1339 / 1583\n",
      "1340 / 1583\n",
      "1341 / 1583\n",
      "1342 / 1583\n",
      "1343 / 1583\n",
      "1344 / 1583\n",
      "1345 / 1583\n",
      "1346 / 1583\n",
      "1347 / 1583\n",
      "1348 / 1583\n",
      "1349 / 1583\n",
      "1350 / 1583\n",
      "1351 / 1583\n",
      "1352 / 1583\n",
      "1353 / 1583\n",
      "1354 / 1583\n",
      "1355 / 1583\n",
      "1356 / 1583\n",
      "1357 / 1583\n",
      "1358 / 1583\n",
      "1359 / 1583\n",
      "1360 / 1583\n",
      "1361 / 1583\n",
      "1362 / 1583\n",
      "1363 / 1583\n",
      "1364 / 1583\n",
      "1365 / 1583\n",
      "1366 / 1583\n",
      "1367 / 1583\n",
      "1368 / 1583\n",
      "1369 / 1583\n",
      "1370 / 1583\n",
      "1371 / 1583\n",
      "1372 / 1583\n",
      "1373 / 1583\n",
      "1374 / 1583\n",
      "1375 / 1583\n",
      "1376 / 1583\n",
      "1377 / 1583\n",
      "1378 / 1583\n",
      "1379 / 1583\n",
      "1380 / 1583\n",
      "1381 / 1583\n",
      "1382 / 1583\n",
      "1383 / 1583\n",
      "1384 / 1583\n",
      "1385 / 1583\n",
      "1386 / 1583\n",
      "1387 / 1583\n",
      "1388 / 1583\n",
      "1389 / 1583\n",
      "1390 / 1583\n",
      "1391 / 1583\n",
      "1392 / 1583\n",
      "1393 / 1583\n",
      "1394 / 1583\n",
      "1395 / 1583\n",
      "1396 / 1583\n",
      "1397 / 1583\n",
      "1398 / 1583\n",
      "1399 / 1583\n",
      "1400 / 1583\n",
      "1401 / 1583\n",
      "1402 / 1583\n",
      "1403 / 1583\n",
      "1404 / 1583\n",
      "1405 / 1583\n",
      "1406 / 1583\n",
      "1407 / 1583\n",
      "1408 / 1583\n",
      "1409 / 1583\n",
      "1410 / 1583\n",
      "1411 / 1583\n",
      "1412 / 1583\n",
      "1413 / 1583\n",
      "1414 / 1583\n",
      "1415 / 1583\n",
      "1416 / 1583\n",
      "1417 / 1583\n",
      "1418 / 1583\n",
      "1419 / 1583\n",
      "1420 / 1583\n",
      "1421 / 1583\n",
      "1422 / 1583\n",
      "1423 / 1583\n",
      "1424 / 1583\n",
      "1425 / 1583\n",
      "1426 / 1583\n",
      "1427 / 1583\n",
      "1428 / 1583\n",
      "1429 / 1583\n",
      "1430 / 1583\n",
      "1431 / 1583\n",
      "1432 / 1583\n",
      "1433 / 1583\n",
      "1434 / 1583\n",
      "1435 / 1583\n",
      "1436 / 1583\n",
      "1437 / 1583\n",
      "1438 / 1583\n",
      "1439 / 1583\n",
      "1440 / 1583\n",
      "1441 / 1583\n",
      "1442 / 1583\n",
      "1443 / 1583\n",
      "1444 / 1583\n",
      "1445 / 1583\n",
      "1446 / 1583\n",
      "1447 / 1583\n",
      "1448 / 1583\n",
      "1449 / 1583\n",
      "1450 / 1583\n",
      "1451 / 1583\n",
      "1452 / 1583\n",
      "1453 / 1583\n",
      "1454 / 1583\n",
      "1455 / 1583\n",
      "1456 / 1583\n",
      "1457 / 1583\n",
      "1458 / 1583\n",
      "1459 / 1583\n",
      "1460 / 1583\n",
      "1461 / 1583\n",
      "1462 / 1583\n",
      "1463 / 1583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464 / 1583\n",
      "1465 / 1583\n",
      "1466 / 1583\n",
      "1467 / 1583\n",
      "1468 / 1583\n",
      "1469 / 1583\n",
      "1470 / 1583\n",
      "1471 / 1583\n",
      "1472 / 1583\n",
      "1473 / 1583\n",
      "1474 / 1583\n",
      "1475 / 1583\n",
      "1476 / 1583\n",
      "1477 / 1583\n",
      "1478 / 1583\n",
      "1479 / 1583\n",
      "1480 / 1583\n",
      "1481 / 1583\n",
      "1482 / 1583\n",
      "1483 / 1583\n",
      "1484 / 1583\n",
      "1485 / 1583\n",
      "1486 / 1583\n",
      "1487 / 1583\n",
      "1488 / 1583\n",
      "1489 / 1583\n",
      "1490 / 1583\n",
      "1491 / 1583\n",
      "1492 / 1583\n",
      "1493 / 1583\n",
      "1494 / 1583\n",
      "1495 / 1583\n",
      "1496 / 1583\n",
      "1497 / 1583\n",
      "1498 / 1583\n",
      "1499 / 1583\n",
      "1500 / 1583\n",
      "1501 / 1583\n",
      "1502 / 1583\n",
      "1503 / 1583\n",
      "1504 / 1583\n",
      "1505 / 1583\n",
      "1506 / 1583\n",
      "1507 / 1583\n",
      "1508 / 1583\n",
      "1509 / 1583\n",
      "1510 / 1583\n",
      "1511 / 1583\n",
      "1512 / 1583\n",
      "1513 / 1583\n",
      "1514 / 1583\n",
      "1515 / 1583\n",
      "1516 / 1583\n",
      "1517 / 1583\n",
      "1518 / 1583\n",
      "1519 / 1583\n",
      "1520 / 1583\n",
      "1521 / 1583\n",
      "1522 / 1583\n",
      "1523 / 1583\n",
      "1524 / 1583\n",
      "1525 / 1583\n",
      "1526 / 1583\n",
      "1527 / 1583\n",
      "1528 / 1583\n",
      "1529 / 1583\n",
      "1530 / 1583\n",
      "1531 / 1583\n",
      "1532 / 1583\n",
      "1533 / 1583\n",
      "1534 / 1583\n",
      "1535 / 1583\n",
      "1536 / 1583\n",
      "1537 / 1583\n",
      "1538 / 1583\n",
      "1539 / 1583\n",
      "1540 / 1583\n",
      "1541 / 1583\n",
      "1542 / 1583\n",
      "1543 / 1583\n",
      "1544 / 1583\n",
      "1545 / 1583\n",
      "1546 / 1583\n",
      "1547 / 1583\n",
      "1548 / 1583\n",
      "1549 / 1583\n",
      "1550 / 1583\n",
      "1551 / 1583\n",
      "1552 / 1583\n",
      "1553 / 1583\n",
      "1554 / 1583\n",
      "1555 / 1583\n",
      "1556 / 1583\n",
      "1557 / 1583\n",
      "1558 / 1583\n",
      "1559 / 1583\n",
      "1560 / 1583\n",
      "1561 / 1583\n",
      "1562 / 1583\n",
      "1563 / 1583\n",
      "1564 / 1583\n",
      "1565 / 1583\n",
      "1566 / 1583\n",
      "1567 / 1583\n",
      "1568 / 1583\n",
      "1569 / 1583\n",
      "1570 / 1583\n",
      "1571 / 1583\n",
      "1572 / 1583\n",
      "1573 / 1583\n",
      "1574 / 1583\n",
      "1575 / 1583\n",
      "1576 / 1583\n",
      "1577 / 1583\n",
      "1578 / 1583\n",
      "1579 / 1583\n",
      "1580 / 1583\n",
      "1581 / 1583\n",
      "1582 / 1583\n",
      "Results saved to: output_data/enron_bert_testing_manhattan.csv\n"
     ]
    }
   ],
   "source": [
    "# test model on same train data\n",
    "test_nn(embeddings_file_path = os.path.join(\"input_data\", \"enron_embeddings.csv\"), \n",
    "        distance_type=\"manhattan\", \n",
    "        file_prefix=\"enron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors - Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nn_similarity import train_nn, test_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: input_data/enron_cosine_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "train_nn(embeddings_file_path = os.path.join(\"input_data\", \"enron_embeddings.csv\"), \n",
    "         distance_type=\"cosine\", \n",
    "         file_prefix=\"enron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1583\n",
      "1 / 1583\n",
      "2 / 1583\n",
      "3 / 1583\n",
      "4 / 1583\n",
      "5 / 1583\n",
      "6 / 1583\n",
      "7 / 1583\n",
      "8 / 1583\n",
      "9 / 1583\n",
      "10 / 1583\n",
      "11 / 1583\n",
      "12 / 1583\n",
      "13 / 1583\n",
      "14 / 1583\n",
      "15 / 1583\n",
      "16 / 1583\n",
      "17 / 1583\n",
      "18 / 1583\n",
      "19 / 1583\n",
      "20 / 1583\n",
      "21 / 1583\n",
      "22 / 1583\n",
      "23 / 1583\n",
      "24 / 1583\n",
      "25 / 1583\n",
      "26 / 1583\n",
      "27 / 1583\n",
      "28 / 1583\n",
      "29 / 1583\n",
      "30 / 1583\n",
      "31 / 1583\n",
      "32 / 1583\n",
      "33 / 1583\n",
      "34 / 1583\n",
      "35 / 1583\n",
      "36 / 1583\n",
      "37 / 1583\n",
      "38 / 1583\n",
      "39 / 1583\n",
      "40 / 1583\n",
      "41 / 1583\n",
      "42 / 1583\n",
      "43 / 1583\n",
      "44 / 1583\n",
      "45 / 1583\n",
      "46 / 1583\n",
      "47 / 1583\n",
      "48 / 1583\n",
      "49 / 1583\n",
      "50 / 1583\n",
      "51 / 1583\n",
      "52 / 1583\n",
      "53 / 1583\n",
      "54 / 1583\n",
      "55 / 1583\n",
      "56 / 1583\n",
      "57 / 1583\n",
      "58 / 1583\n",
      "59 / 1583\n",
      "60 / 1583\n",
      "61 / 1583\n",
      "62 / 1583\n",
      "63 / 1583\n",
      "64 / 1583\n",
      "65 / 1583\n",
      "66 / 1583\n",
      "67 / 1583\n",
      "68 / 1583\n",
      "69 / 1583\n",
      "70 / 1583\n",
      "71 / 1583\n",
      "72 / 1583\n",
      "73 / 1583\n",
      "74 / 1583\n",
      "75 / 1583\n",
      "76 / 1583\n",
      "77 / 1583\n",
      "78 / 1583\n",
      "79 / 1583\n",
      "80 / 1583\n",
      "81 / 1583\n",
      "82 / 1583\n",
      "83 / 1583\n",
      "84 / 1583\n",
      "85 / 1583\n",
      "86 / 1583\n",
      "87 / 1583\n",
      "88 / 1583\n",
      "89 / 1583\n",
      "90 / 1583\n",
      "91 / 1583\n",
      "92 / 1583\n",
      "93 / 1583\n",
      "94 / 1583\n",
      "95 / 1583\n",
      "96 / 1583\n",
      "97 / 1583\n",
      "98 / 1583\n",
      "99 / 1583\n",
      "100 / 1583\n",
      "101 / 1583\n",
      "102 / 1583\n",
      "103 / 1583\n",
      "104 / 1583\n",
      "105 / 1583\n",
      "106 / 1583\n",
      "107 / 1583\n",
      "108 / 1583\n",
      "109 / 1583\n",
      "110 / 1583\n",
      "111 / 1583\n",
      "112 / 1583\n",
      "113 / 1583\n",
      "114 / 1583\n",
      "115 / 1583\n",
      "116 / 1583\n",
      "117 / 1583\n",
      "118 / 1583\n",
      "119 / 1583\n",
      "120 / 1583\n",
      "121 / 1583\n",
      "122 / 1583\n",
      "123 / 1583\n",
      "124 / 1583\n",
      "125 / 1583\n",
      "126 / 1583\n",
      "127 / 1583\n",
      "128 / 1583\n",
      "129 / 1583\n",
      "130 / 1583\n",
      "131 / 1583\n",
      "132 / 1583\n",
      "133 / 1583\n",
      "134 / 1583\n",
      "135 / 1583\n",
      "136 / 1583\n",
      "137 / 1583\n",
      "138 / 1583\n",
      "139 / 1583\n",
      "140 / 1583\n",
      "141 / 1583\n",
      "142 / 1583\n",
      "143 / 1583\n",
      "144 / 1583\n",
      "145 / 1583\n",
      "146 / 1583\n",
      "147 / 1583\n",
      "148 / 1583\n",
      "149 / 1583\n",
      "150 / 1583\n",
      "151 / 1583\n",
      "152 / 1583\n",
      "153 / 1583\n",
      "154 / 1583\n",
      "155 / 1583\n",
      "156 / 1583\n",
      "157 / 1583\n",
      "158 / 1583\n",
      "159 / 1583\n",
      "160 / 1583\n",
      "161 / 1583\n",
      "162 / 1583\n",
      "163 / 1583\n",
      "164 / 1583\n",
      "165 / 1583\n",
      "166 / 1583\n",
      "167 / 1583\n",
      "168 / 1583\n",
      "169 / 1583\n",
      "170 / 1583\n",
      "171 / 1583\n",
      "172 / 1583\n",
      "173 / 1583\n",
      "174 / 1583\n",
      "175 / 1583\n",
      "176 / 1583\n",
      "177 / 1583\n",
      "178 / 1583\n",
      "179 / 1583\n",
      "180 / 1583\n",
      "181 / 1583\n",
      "182 / 1583\n",
      "183 / 1583\n",
      "184 / 1583\n",
      "185 / 1583\n",
      "186 / 1583\n",
      "187 / 1583\n",
      "188 / 1583\n",
      "189 / 1583\n",
      "190 / 1583\n",
      "191 / 1583\n",
      "192 / 1583\n",
      "193 / 1583\n",
      "194 / 1583\n",
      "195 / 1583\n",
      "196 / 1583\n",
      "197 / 1583\n",
      "198 / 1583\n",
      "199 / 1583\n",
      "200 / 1583\n",
      "201 / 1583\n",
      "202 / 1583\n",
      "203 / 1583\n",
      "204 / 1583\n",
      "205 / 1583\n",
      "206 / 1583\n",
      "207 / 1583\n",
      "208 / 1583\n",
      "209 / 1583\n",
      "210 / 1583\n",
      "211 / 1583\n",
      "212 / 1583\n",
      "213 / 1583\n",
      "214 / 1583\n",
      "215 / 1583\n",
      "216 / 1583\n",
      "217 / 1583\n",
      "218 / 1583\n",
      "219 / 1583\n",
      "220 / 1583\n",
      "221 / 1583\n",
      "222 / 1583\n",
      "223 / 1583\n",
      "224 / 1583\n",
      "225 / 1583\n",
      "226 / 1583\n",
      "227 / 1583\n",
      "228 / 1583\n",
      "229 / 1583\n",
      "230 / 1583\n",
      "231 / 1583\n",
      "232 / 1583\n",
      "233 / 1583\n",
      "234 / 1583\n",
      "235 / 1583\n",
      "236 / 1583\n",
      "237 / 1583\n",
      "238 / 1583\n",
      "239 / 1583\n",
      "240 / 1583\n",
      "241 / 1583\n",
      "242 / 1583\n",
      "243 / 1583\n",
      "244 / 1583\n",
      "245 / 1583\n",
      "246 / 1583\n",
      "247 / 1583\n",
      "248 / 1583\n",
      "249 / 1583\n",
      "250 / 1583\n",
      "251 / 1583\n",
      "252 / 1583\n",
      "253 / 1583\n",
      "254 / 1583\n",
      "255 / 1583\n",
      "256 / 1583\n",
      "257 / 1583\n",
      "258 / 1583\n",
      "259 / 1583\n",
      "260 / 1583\n",
      "261 / 1583\n",
      "262 / 1583\n",
      "263 / 1583\n",
      "264 / 1583\n",
      "265 / 1583\n",
      "266 / 1583\n",
      "267 / 1583\n",
      "268 / 1583\n",
      "269 / 1583\n",
      "270 / 1583\n",
      "271 / 1583\n",
      "272 / 1583\n",
      "273 / 1583\n",
      "274 / 1583\n",
      "275 / 1583\n",
      "276 / 1583\n",
      "277 / 1583\n",
      "278 / 1583\n",
      "279 / 1583\n",
      "280 / 1583\n",
      "281 / 1583\n",
      "282 / 1583\n",
      "283 / 1583\n",
      "284 / 1583\n",
      "285 / 1583\n",
      "286 / 1583\n",
      "287 / 1583\n",
      "288 / 1583\n",
      "289 / 1583\n",
      "290 / 1583\n",
      "291 / 1583\n",
      "292 / 1583\n",
      "293 / 1583\n",
      "294 / 1583\n",
      "295 / 1583\n",
      "296 / 1583\n",
      "297 / 1583\n",
      "298 / 1583\n",
      "299 / 1583\n",
      "300 / 1583\n",
      "301 / 1583\n",
      "302 / 1583\n",
      "303 / 1583\n",
      "304 / 1583\n",
      "305 / 1583\n",
      "306 / 1583\n",
      "307 / 1583\n",
      "308 / 1583\n",
      "309 / 1583\n",
      "310 / 1583\n",
      "311 / 1583\n",
      "312 / 1583\n",
      "313 / 1583\n",
      "314 / 1583\n",
      "315 / 1583\n",
      "316 / 1583\n",
      "317 / 1583\n",
      "318 / 1583\n",
      "319 / 1583\n",
      "320 / 1583\n",
      "321 / 1583\n",
      "322 / 1583\n",
      "323 / 1583\n",
      "324 / 1583\n",
      "325 / 1583\n",
      "326 / 1583\n",
      "327 / 1583\n",
      "328 / 1583\n",
      "329 / 1583\n",
      "330 / 1583\n",
      "331 / 1583\n",
      "332 / 1583\n",
      "333 / 1583\n",
      "334 / 1583\n",
      "335 / 1583\n",
      "336 / 1583\n",
      "337 / 1583\n",
      "338 / 1583\n",
      "339 / 1583\n",
      "340 / 1583\n",
      "341 / 1583\n",
      "342 / 1583\n",
      "343 / 1583\n",
      "344 / 1583\n",
      "345 / 1583\n",
      "346 / 1583\n",
      "347 / 1583\n",
      "348 / 1583\n",
      "349 / 1583\n",
      "350 / 1583\n",
      "351 / 1583\n",
      "352 / 1583\n",
      "353 / 1583\n",
      "354 / 1583\n",
      "355 / 1583\n",
      "356 / 1583\n",
      "357 / 1583\n",
      "358 / 1583\n",
      "359 / 1583\n",
      "360 / 1583\n",
      "361 / 1583\n",
      "362 / 1583\n",
      "363 / 1583\n",
      "364 / 1583\n",
      "365 / 1583\n",
      "366 / 1583\n",
      "367 / 1583\n",
      "368 / 1583\n",
      "369 / 1583\n",
      "370 / 1583\n",
      "371 / 1583\n",
      "372 / 1583\n",
      "373 / 1583\n",
      "374 / 1583\n",
      "375 / 1583\n",
      "376 / 1583\n",
      "377 / 1583\n",
      "378 / 1583\n",
      "379 / 1583\n",
      "380 / 1583\n",
      "381 / 1583\n",
      "382 / 1583\n",
      "383 / 1583\n",
      "384 / 1583\n",
      "385 / 1583\n",
      "386 / 1583\n",
      "387 / 1583\n",
      "388 / 1583\n",
      "389 / 1583\n",
      "390 / 1583\n",
      "391 / 1583\n",
      "392 / 1583\n",
      "393 / 1583\n",
      "394 / 1583\n",
      "395 / 1583\n",
      "396 / 1583\n",
      "397 / 1583\n",
      "398 / 1583\n",
      "399 / 1583\n",
      "400 / 1583\n",
      "401 / 1583\n",
      "402 / 1583\n",
      "403 / 1583\n",
      "404 / 1583\n",
      "405 / 1583\n",
      "406 / 1583\n",
      "407 / 1583\n",
      "408 / 1583\n",
      "409 / 1583\n",
      "410 / 1583\n",
      "411 / 1583\n",
      "412 / 1583\n",
      "413 / 1583\n",
      "414 / 1583\n",
      "415 / 1583\n",
      "416 / 1583\n",
      "417 / 1583\n",
      "418 / 1583\n",
      "419 / 1583\n",
      "420 / 1583\n",
      "421 / 1583\n",
      "422 / 1583\n",
      "423 / 1583\n",
      "424 / 1583\n",
      "425 / 1583\n",
      "426 / 1583\n",
      "427 / 1583\n",
      "428 / 1583\n",
      "429 / 1583\n",
      "430 / 1583\n",
      "431 / 1583\n",
      "432 / 1583\n",
      "433 / 1583\n",
      "434 / 1583\n",
      "435 / 1583\n",
      "436 / 1583\n",
      "437 / 1583\n",
      "438 / 1583\n",
      "439 / 1583\n",
      "440 / 1583\n",
      "441 / 1583\n",
      "442 / 1583\n",
      "443 / 1583\n",
      "444 / 1583\n",
      "445 / 1583\n",
      "446 / 1583\n",
      "447 / 1583\n",
      "448 / 1583\n",
      "449 / 1583\n",
      "450 / 1583\n",
      "451 / 1583\n",
      "452 / 1583\n",
      "453 / 1583\n",
      "454 / 1583\n",
      "455 / 1583\n",
      "456 / 1583\n",
      "457 / 1583\n",
      "458 / 1583\n",
      "459 / 1583\n",
      "460 / 1583\n",
      "461 / 1583\n",
      "462 / 1583\n",
      "463 / 1583\n",
      "464 / 1583\n",
      "465 / 1583\n",
      "466 / 1583\n",
      "467 / 1583\n",
      "468 / 1583\n",
      "469 / 1583\n",
      "470 / 1583\n",
      "471 / 1583\n",
      "472 / 1583\n",
      "473 / 1583\n",
      "474 / 1583\n",
      "475 / 1583\n",
      "476 / 1583\n",
      "477 / 1583\n",
      "478 / 1583\n",
      "479 / 1583\n",
      "480 / 1583\n",
      "481 / 1583\n",
      "482 / 1583\n",
      "483 / 1583\n",
      "484 / 1583\n",
      "485 / 1583\n",
      "486 / 1583\n",
      "487 / 1583\n",
      "488 / 1583\n",
      "489 / 1583\n",
      "490 / 1583\n",
      "491 / 1583\n",
      "492 / 1583\n",
      "493 / 1583\n",
      "494 / 1583\n",
      "495 / 1583\n",
      "496 / 1583\n",
      "497 / 1583\n",
      "498 / 1583\n",
      "499 / 1583\n",
      "500 / 1583\n",
      "501 / 1583\n",
      "502 / 1583\n",
      "503 / 1583\n",
      "504 / 1583\n",
      "505 / 1583\n",
      "506 / 1583\n",
      "507 / 1583\n",
      "508 / 1583\n",
      "509 / 1583\n",
      "510 / 1583\n",
      "511 / 1583\n",
      "512 / 1583\n",
      "513 / 1583\n",
      "514 / 1583\n",
      "515 / 1583\n",
      "516 / 1583\n",
      "517 / 1583\n",
      "518 / 1583\n",
      "519 / 1583\n",
      "520 / 1583\n",
      "521 / 1583\n",
      "522 / 1583\n",
      "523 / 1583\n",
      "524 / 1583\n",
      "525 / 1583\n",
      "526 / 1583\n",
      "527 / 1583\n",
      "528 / 1583\n",
      "529 / 1583\n",
      "530 / 1583\n",
      "531 / 1583\n",
      "532 / 1583\n",
      "533 / 1583\n",
      "534 / 1583\n",
      "535 / 1583\n",
      "536 / 1583\n",
      "537 / 1583\n",
      "538 / 1583\n",
      "539 / 1583\n",
      "540 / 1583\n",
      "541 / 1583\n",
      "542 / 1583\n",
      "543 / 1583\n",
      "544 / 1583\n",
      "545 / 1583\n",
      "546 / 1583\n",
      "547 / 1583\n",
      "548 / 1583\n",
      "549 / 1583\n",
      "550 / 1583\n",
      "551 / 1583\n",
      "552 / 1583\n",
      "553 / 1583\n",
      "554 / 1583\n",
      "555 / 1583\n",
      "556 / 1583\n",
      "557 / 1583\n",
      "558 / 1583\n",
      "559 / 1583\n",
      "560 / 1583\n",
      "561 / 1583\n",
      "562 / 1583\n",
      "563 / 1583\n",
      "564 / 1583\n",
      "565 / 1583\n",
      "566 / 1583\n",
      "567 / 1583\n",
      "568 / 1583\n",
      "569 / 1583\n",
      "570 / 1583\n",
      "571 / 1583\n",
      "572 / 1583\n",
      "573 / 1583\n",
      "574 / 1583\n",
      "575 / 1583\n",
      "576 / 1583\n",
      "577 / 1583\n",
      "578 / 1583\n",
      "579 / 1583\n",
      "580 / 1583\n",
      "581 / 1583\n",
      "582 / 1583\n",
      "583 / 1583\n",
      "584 / 1583\n",
      "585 / 1583\n",
      "586 / 1583\n",
      "587 / 1583\n",
      "588 / 1583\n",
      "589 / 1583\n",
      "590 / 1583\n",
      "591 / 1583\n",
      "592 / 1583\n",
      "593 / 1583\n",
      "594 / 1583\n",
      "595 / 1583\n",
      "596 / 1583\n",
      "597 / 1583\n",
      "598 / 1583\n",
      "599 / 1583\n",
      "600 / 1583\n",
      "601 / 1583\n",
      "602 / 1583\n",
      "603 / 1583\n",
      "604 / 1583\n",
      "605 / 1583\n",
      "606 / 1583\n",
      "607 / 1583\n",
      "608 / 1583\n",
      "609 / 1583\n",
      "610 / 1583\n",
      "611 / 1583\n",
      "612 / 1583\n",
      "613 / 1583\n",
      "614 / 1583\n",
      "615 / 1583\n",
      "616 / 1583\n",
      "617 / 1583\n",
      "618 / 1583\n",
      "619 / 1583\n",
      "620 / 1583\n",
      "621 / 1583\n",
      "622 / 1583\n",
      "623 / 1583\n",
      "624 / 1583\n",
      "625 / 1583\n",
      "626 / 1583\n",
      "627 / 1583\n",
      "628 / 1583\n",
      "629 / 1583\n",
      "630 / 1583\n",
      "631 / 1583\n",
      "632 / 1583\n",
      "633 / 1583\n",
      "634 / 1583\n",
      "635 / 1583\n",
      "636 / 1583\n",
      "637 / 1583\n",
      "638 / 1583\n",
      "639 / 1583\n",
      "640 / 1583\n",
      "641 / 1583\n",
      "642 / 1583\n",
      "643 / 1583\n",
      "644 / 1583\n",
      "645 / 1583\n",
      "646 / 1583\n",
      "647 / 1583\n",
      "648 / 1583\n",
      "649 / 1583\n",
      "650 / 1583\n",
      "651 / 1583\n",
      "652 / 1583\n",
      "653 / 1583\n",
      "654 / 1583\n",
      "655 / 1583\n",
      "656 / 1583\n",
      "657 / 1583\n",
      "658 / 1583\n",
      "659 / 1583\n",
      "660 / 1583\n",
      "661 / 1583\n",
      "662 / 1583\n",
      "663 / 1583\n",
      "664 / 1583\n",
      "665 / 1583\n",
      "666 / 1583\n",
      "667 / 1583\n",
      "668 / 1583\n",
      "669 / 1583\n",
      "670 / 1583\n",
      "671 / 1583\n",
      "672 / 1583\n",
      "673 / 1583\n",
      "674 / 1583\n",
      "675 / 1583\n",
      "676 / 1583\n",
      "677 / 1583\n",
      "678 / 1583\n",
      "679 / 1583\n",
      "680 / 1583\n",
      "681 / 1583\n",
      "682 / 1583\n",
      "683 / 1583\n",
      "684 / 1583\n",
      "685 / 1583\n",
      "686 / 1583\n",
      "687 / 1583\n",
      "688 / 1583\n",
      "689 / 1583\n",
      "690 / 1583\n",
      "691 / 1583\n",
      "692 / 1583\n",
      "693 / 1583\n",
      "694 / 1583\n",
      "695 / 1583\n",
      "696 / 1583\n",
      "697 / 1583\n",
      "698 / 1583\n",
      "699 / 1583\n",
      "700 / 1583\n",
      "701 / 1583\n",
      "702 / 1583\n",
      "703 / 1583\n",
      "704 / 1583\n",
      "705 / 1583\n",
      "706 / 1583\n",
      "707 / 1583\n",
      "708 / 1583\n",
      "709 / 1583\n",
      "710 / 1583\n",
      "711 / 1583\n",
      "712 / 1583\n",
      "713 / 1583\n",
      "714 / 1583\n",
      "715 / 1583\n",
      "716 / 1583\n",
      "717 / 1583\n",
      "718 / 1583\n",
      "719 / 1583\n",
      "720 / 1583\n",
      "721 / 1583\n",
      "722 / 1583\n",
      "723 / 1583\n",
      "724 / 1583\n",
      "725 / 1583\n",
      "726 / 1583\n",
      "727 / 1583\n",
      "728 / 1583\n",
      "729 / 1583\n",
      "730 / 1583\n",
      "731 / 1583\n",
      "732 / 1583\n",
      "733 / 1583\n",
      "734 / 1583\n",
      "735 / 1583\n",
      "736 / 1583\n",
      "737 / 1583\n",
      "738 / 1583\n",
      "739 / 1583\n",
      "740 / 1583\n",
      "741 / 1583\n",
      "742 / 1583\n",
      "743 / 1583\n",
      "744 / 1583\n",
      "745 / 1583\n",
      "746 / 1583\n",
      "747 / 1583\n",
      "748 / 1583\n",
      "749 / 1583\n",
      "750 / 1583\n",
      "751 / 1583\n",
      "752 / 1583\n",
      "753 / 1583\n",
      "754 / 1583\n",
      "755 / 1583\n",
      "756 / 1583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757 / 1583\n",
      "758 / 1583\n",
      "759 / 1583\n",
      "760 / 1583\n",
      "761 / 1583\n",
      "762 / 1583\n",
      "763 / 1583\n",
      "764 / 1583\n",
      "765 / 1583\n",
      "766 / 1583\n",
      "767 / 1583\n",
      "768 / 1583\n",
      "769 / 1583\n",
      "770 / 1583\n",
      "771 / 1583\n",
      "772 / 1583\n",
      "773 / 1583\n",
      "774 / 1583\n",
      "775 / 1583\n",
      "776 / 1583\n",
      "777 / 1583\n",
      "778 / 1583\n",
      "779 / 1583\n",
      "780 / 1583\n",
      "781 / 1583\n",
      "782 / 1583\n",
      "783 / 1583\n",
      "784 / 1583\n",
      "785 / 1583\n",
      "786 / 1583\n",
      "787 / 1583\n",
      "788 / 1583\n",
      "789 / 1583\n",
      "790 / 1583\n",
      "791 / 1583\n",
      "792 / 1583\n",
      "793 / 1583\n",
      "794 / 1583\n",
      "795 / 1583\n",
      "796 / 1583\n",
      "797 / 1583\n",
      "798 / 1583\n",
      "799 / 1583\n",
      "800 / 1583\n",
      "801 / 1583\n",
      "802 / 1583\n",
      "803 / 1583\n",
      "804 / 1583\n",
      "805 / 1583\n",
      "806 / 1583\n",
      "807 / 1583\n",
      "808 / 1583\n",
      "809 / 1583\n",
      "810 / 1583\n",
      "811 / 1583\n",
      "812 / 1583\n",
      "813 / 1583\n",
      "814 / 1583\n",
      "815 / 1583\n",
      "816 / 1583\n",
      "817 / 1583\n",
      "818 / 1583\n",
      "819 / 1583\n",
      "820 / 1583\n",
      "821 / 1583\n",
      "822 / 1583\n",
      "823 / 1583\n",
      "824 / 1583\n",
      "825 / 1583\n",
      "826 / 1583\n",
      "827 / 1583\n",
      "828 / 1583\n",
      "829 / 1583\n",
      "830 / 1583\n",
      "831 / 1583\n",
      "832 / 1583\n",
      "833 / 1583\n",
      "834 / 1583\n",
      "835 / 1583\n",
      "836 / 1583\n",
      "837 / 1583\n",
      "838 / 1583\n",
      "839 / 1583\n",
      "840 / 1583\n",
      "841 / 1583\n",
      "842 / 1583\n",
      "843 / 1583\n",
      "844 / 1583\n",
      "845 / 1583\n",
      "846 / 1583\n",
      "847 / 1583\n",
      "848 / 1583\n",
      "849 / 1583\n",
      "850 / 1583\n",
      "851 / 1583\n",
      "852 / 1583\n",
      "853 / 1583\n",
      "854 / 1583\n",
      "855 / 1583\n",
      "856 / 1583\n",
      "857 / 1583\n",
      "858 / 1583\n",
      "859 / 1583\n",
      "860 / 1583\n",
      "861 / 1583\n",
      "862 / 1583\n",
      "863 / 1583\n",
      "864 / 1583\n",
      "865 / 1583\n",
      "866 / 1583\n",
      "867 / 1583\n",
      "868 / 1583\n",
      "869 / 1583\n",
      "870 / 1583\n",
      "871 / 1583\n",
      "872 / 1583\n",
      "873 / 1583\n",
      "874 / 1583\n",
      "875 / 1583\n",
      "876 / 1583\n",
      "877 / 1583\n",
      "878 / 1583\n",
      "879 / 1583\n",
      "880 / 1583\n",
      "881 / 1583\n",
      "882 / 1583\n",
      "883 / 1583\n",
      "884 / 1583\n",
      "885 / 1583\n",
      "886 / 1583\n",
      "887 / 1583\n",
      "888 / 1583\n",
      "889 / 1583\n",
      "890 / 1583\n",
      "891 / 1583\n",
      "892 / 1583\n",
      "893 / 1583\n",
      "894 / 1583\n",
      "895 / 1583\n",
      "896 / 1583\n",
      "897 / 1583\n",
      "898 / 1583\n",
      "899 / 1583\n",
      "900 / 1583\n",
      "901 / 1583\n",
      "902 / 1583\n",
      "903 / 1583\n",
      "904 / 1583\n",
      "905 / 1583\n",
      "906 / 1583\n",
      "907 / 1583\n",
      "908 / 1583\n",
      "909 / 1583\n",
      "910 / 1583\n",
      "911 / 1583\n",
      "912 / 1583\n",
      "913 / 1583\n",
      "914 / 1583\n",
      "915 / 1583\n",
      "916 / 1583\n",
      "917 / 1583\n",
      "918 / 1583\n",
      "919 / 1583\n",
      "920 / 1583\n",
      "921 / 1583\n",
      "922 / 1583\n",
      "923 / 1583\n",
      "924 / 1583\n",
      "925 / 1583\n",
      "926 / 1583\n",
      "927 / 1583\n",
      "928 / 1583\n",
      "929 / 1583\n",
      "930 / 1583\n",
      "931 / 1583\n",
      "932 / 1583\n",
      "933 / 1583\n",
      "934 / 1583\n",
      "935 / 1583\n",
      "936 / 1583\n",
      "937 / 1583\n",
      "938 / 1583\n",
      "939 / 1583\n",
      "940 / 1583\n",
      "941 / 1583\n",
      "942 / 1583\n",
      "943 / 1583\n",
      "944 / 1583\n",
      "945 / 1583\n",
      "946 / 1583\n",
      "947 / 1583\n",
      "948 / 1583\n",
      "949 / 1583\n",
      "950 / 1583\n",
      "951 / 1583\n",
      "952 / 1583\n",
      "953 / 1583\n",
      "954 / 1583\n",
      "955 / 1583\n",
      "956 / 1583\n",
      "957 / 1583\n",
      "958 / 1583\n",
      "959 / 1583\n",
      "960 / 1583\n",
      "961 / 1583\n",
      "962 / 1583\n",
      "963 / 1583\n",
      "964 / 1583\n",
      "965 / 1583\n",
      "966 / 1583\n",
      "967 / 1583\n",
      "968 / 1583\n",
      "969 / 1583\n",
      "970 / 1583\n",
      "971 / 1583\n",
      "972 / 1583\n",
      "973 / 1583\n",
      "974 / 1583\n",
      "975 / 1583\n",
      "976 / 1583\n",
      "977 / 1583\n",
      "978 / 1583\n",
      "979 / 1583\n",
      "980 / 1583\n",
      "981 / 1583\n",
      "982 / 1583\n",
      "983 / 1583\n",
      "984 / 1583\n",
      "985 / 1583\n",
      "986 / 1583\n",
      "987 / 1583\n",
      "988 / 1583\n",
      "989 / 1583\n",
      "990 / 1583\n",
      "991 / 1583\n",
      "992 / 1583\n",
      "993 / 1583\n",
      "994 / 1583\n",
      "995 / 1583\n",
      "996 / 1583\n",
      "997 / 1583\n",
      "998 / 1583\n",
      "999 / 1583\n",
      "1000 / 1583\n",
      "1001 / 1583\n",
      "1002 / 1583\n",
      "1003 / 1583\n",
      "1004 / 1583\n",
      "1005 / 1583\n",
      "1006 / 1583\n",
      "1007 / 1583\n",
      "1008 / 1583\n",
      "1009 / 1583\n",
      "1010 / 1583\n",
      "1011 / 1583\n",
      "1012 / 1583\n",
      "1013 / 1583\n",
      "1014 / 1583\n",
      "1015 / 1583\n",
      "1016 / 1583\n",
      "1017 / 1583\n",
      "1018 / 1583\n",
      "1019 / 1583\n",
      "1020 / 1583\n",
      "1021 / 1583\n",
      "1022 / 1583\n",
      "1023 / 1583\n",
      "1024 / 1583\n",
      "1025 / 1583\n",
      "1026 / 1583\n",
      "1027 / 1583\n",
      "1028 / 1583\n",
      "1029 / 1583\n",
      "1030 / 1583\n",
      "1031 / 1583\n",
      "1032 / 1583\n",
      "1033 / 1583\n",
      "1034 / 1583\n",
      "1035 / 1583\n",
      "1036 / 1583\n",
      "1037 / 1583\n",
      "1038 / 1583\n",
      "1039 / 1583\n",
      "1040 / 1583\n",
      "1041 / 1583\n",
      "1042 / 1583\n",
      "1043 / 1583\n",
      "1044 / 1583\n",
      "1045 / 1583\n",
      "1046 / 1583\n",
      "1047 / 1583\n",
      "1048 / 1583\n",
      "1049 / 1583\n",
      "1050 / 1583\n",
      "1051 / 1583\n",
      "1052 / 1583\n",
      "1053 / 1583\n",
      "1054 / 1583\n",
      "1055 / 1583\n",
      "1056 / 1583\n",
      "1057 / 1583\n",
      "1058 / 1583\n",
      "1059 / 1583\n",
      "1060 / 1583\n",
      "1061 / 1583\n",
      "1062 / 1583\n",
      "1063 / 1583\n",
      "1064 / 1583\n",
      "1065 / 1583\n",
      "1066 / 1583\n",
      "1067 / 1583\n",
      "1068 / 1583\n",
      "1069 / 1583\n",
      "1070 / 1583\n",
      "1071 / 1583\n",
      "1072 / 1583\n",
      "1073 / 1583\n",
      "1074 / 1583\n",
      "1075 / 1583\n",
      "1076 / 1583\n",
      "1077 / 1583\n",
      "1078 / 1583\n",
      "1079 / 1583\n",
      "1080 / 1583\n",
      "1081 / 1583\n",
      "1082 / 1583\n",
      "1083 / 1583\n",
      "1084 / 1583\n",
      "1085 / 1583\n",
      "1086 / 1583\n",
      "1087 / 1583\n",
      "1088 / 1583\n",
      "1089 / 1583\n",
      "1090 / 1583\n",
      "1091 / 1583\n",
      "1092 / 1583\n",
      "1093 / 1583\n",
      "1094 / 1583\n",
      "1095 / 1583\n",
      "1096 / 1583\n",
      "1097 / 1583\n",
      "1098 / 1583\n",
      "1099 / 1583\n",
      "1100 / 1583\n",
      "1101 / 1583\n",
      "1102 / 1583\n",
      "1103 / 1583\n",
      "1104 / 1583\n",
      "1105 / 1583\n",
      "1106 / 1583\n",
      "1107 / 1583\n",
      "1108 / 1583\n",
      "1109 / 1583\n",
      "1110 / 1583\n",
      "1111 / 1583\n",
      "1112 / 1583\n",
      "1113 / 1583\n",
      "1114 / 1583\n",
      "1115 / 1583\n",
      "1116 / 1583\n",
      "1117 / 1583\n",
      "1118 / 1583\n",
      "1119 / 1583\n",
      "1120 / 1583\n",
      "1121 / 1583\n",
      "1122 / 1583\n",
      "1123 / 1583\n",
      "1124 / 1583\n",
      "1125 / 1583\n",
      "1126 / 1583\n",
      "1127 / 1583\n",
      "1128 / 1583\n",
      "1129 / 1583\n",
      "1130 / 1583\n",
      "1131 / 1583\n",
      "1132 / 1583\n",
      "1133 / 1583\n",
      "1134 / 1583\n",
      "1135 / 1583\n",
      "1136 / 1583\n",
      "1137 / 1583\n",
      "1138 / 1583\n",
      "1139 / 1583\n",
      "1140 / 1583\n",
      "1141 / 1583\n",
      "1142 / 1583\n",
      "1143 / 1583\n",
      "1144 / 1583\n",
      "1145 / 1583\n",
      "1146 / 1583\n",
      "1147 / 1583\n",
      "1148 / 1583\n",
      "1149 / 1583\n",
      "1150 / 1583\n",
      "1151 / 1583\n",
      "1152 / 1583\n",
      "1153 / 1583\n",
      "1154 / 1583\n",
      "1155 / 1583\n",
      "1156 / 1583\n",
      "1157 / 1583\n",
      "1158 / 1583\n",
      "1159 / 1583\n",
      "1160 / 1583\n",
      "1161 / 1583\n",
      "1162 / 1583\n",
      "1163 / 1583\n",
      "1164 / 1583\n",
      "1165 / 1583\n",
      "1166 / 1583\n",
      "1167 / 1583\n",
      "1168 / 1583\n",
      "1169 / 1583\n",
      "1170 / 1583\n",
      "1171 / 1583\n",
      "1172 / 1583\n",
      "1173 / 1583\n",
      "1174 / 1583\n",
      "1175 / 1583\n",
      "1176 / 1583\n",
      "1177 / 1583\n",
      "1178 / 1583\n",
      "1179 / 1583\n",
      "1180 / 1583\n",
      "1181 / 1583\n",
      "1182 / 1583\n",
      "1183 / 1583\n",
      "1184 / 1583\n",
      "1185 / 1583\n",
      "1186 / 1583\n",
      "1187 / 1583\n",
      "1188 / 1583\n",
      "1189 / 1583\n",
      "1190 / 1583\n",
      "1191 / 1583\n",
      "1192 / 1583\n",
      "1193 / 1583\n",
      "1194 / 1583\n",
      "1195 / 1583\n",
      "1196 / 1583\n",
      "1197 / 1583\n",
      "1198 / 1583\n",
      "1199 / 1583\n",
      "1200 / 1583\n",
      "1201 / 1583\n",
      "1202 / 1583\n",
      "1203 / 1583\n",
      "1204 / 1583\n",
      "1205 / 1583\n",
      "1206 / 1583\n",
      "1207 / 1583\n",
      "1208 / 1583\n",
      "1209 / 1583\n",
      "1210 / 1583\n",
      "1211 / 1583\n",
      "1212 / 1583\n",
      "1213 / 1583\n",
      "1214 / 1583\n",
      "1215 / 1583\n",
      "1216 / 1583\n",
      "1217 / 1583\n",
      "1218 / 1583\n",
      "1219 / 1583\n",
      "1220 / 1583\n",
      "1221 / 1583\n",
      "1222 / 1583\n",
      "1223 / 1583\n",
      "1224 / 1583\n",
      "1225 / 1583\n",
      "1226 / 1583\n",
      "1227 / 1583\n",
      "1228 / 1583\n",
      "1229 / 1583\n",
      "1230 / 1583\n",
      "1231 / 1583\n",
      "1232 / 1583\n",
      "1233 / 1583\n",
      "1234 / 1583\n",
      "1235 / 1583\n",
      "1236 / 1583\n",
      "1237 / 1583\n",
      "1238 / 1583\n",
      "1239 / 1583\n",
      "1240 / 1583\n",
      "1241 / 1583\n",
      "1242 / 1583\n",
      "1243 / 1583\n",
      "1244 / 1583\n",
      "1245 / 1583\n",
      "1246 / 1583\n",
      "1247 / 1583\n",
      "1248 / 1583\n",
      "1249 / 1583\n",
      "1250 / 1583\n",
      "1251 / 1583\n",
      "1252 / 1583\n",
      "1253 / 1583\n",
      "1254 / 1583\n",
      "1255 / 1583\n",
      "1256 / 1583\n",
      "1257 / 1583\n",
      "1258 / 1583\n",
      "1259 / 1583\n",
      "1260 / 1583\n",
      "1261 / 1583\n",
      "1262 / 1583\n",
      "1263 / 1583\n",
      "1264 / 1583\n",
      "1265 / 1583\n",
      "1266 / 1583\n",
      "1267 / 1583\n",
      "1268 / 1583\n",
      "1269 / 1583\n",
      "1270 / 1583\n",
      "1271 / 1583\n",
      "1272 / 1583\n",
      "1273 / 1583\n",
      "1274 / 1583\n",
      "1275 / 1583\n",
      "1276 / 1583\n",
      "1277 / 1583\n",
      "1278 / 1583\n",
      "1279 / 1583\n",
      "1280 / 1583\n",
      "1281 / 1583\n",
      "1282 / 1583\n",
      "1283 / 1583\n",
      "1284 / 1583\n",
      "1285 / 1583\n",
      "1286 / 1583\n",
      "1287 / 1583\n",
      "1288 / 1583\n",
      "1289 / 1583\n",
      "1290 / 1583\n",
      "1291 / 1583\n",
      "1292 / 1583\n",
      "1293 / 1583\n",
      "1294 / 1583\n",
      "1295 / 1583\n",
      "1296 / 1583\n",
      "1297 / 1583\n",
      "1298 / 1583\n",
      "1299 / 1583\n",
      "1300 / 1583\n",
      "1301 / 1583\n",
      "1302 / 1583\n",
      "1303 / 1583\n",
      "1304 / 1583\n",
      "1305 / 1583\n",
      "1306 / 1583\n",
      "1307 / 1583\n",
      "1308 / 1583\n",
      "1309 / 1583\n",
      "1310 / 1583\n",
      "1311 / 1583\n",
      "1312 / 1583\n",
      "1313 / 1583\n",
      "1314 / 1583\n",
      "1315 / 1583\n",
      "1316 / 1583\n",
      "1317 / 1583\n",
      "1318 / 1583\n",
      "1319 / 1583\n",
      "1320 / 1583\n",
      "1321 / 1583\n",
      "1322 / 1583\n",
      "1323 / 1583\n",
      "1324 / 1583\n",
      "1325 / 1583\n",
      "1326 / 1583\n",
      "1327 / 1583\n",
      "1328 / 1583\n",
      "1329 / 1583\n",
      "1330 / 1583\n",
      "1331 / 1583\n",
      "1332 / 1583\n",
      "1333 / 1583\n",
      "1334 / 1583\n",
      "1335 / 1583\n",
      "1336 / 1583\n",
      "1337 / 1583\n",
      "1338 / 1583\n",
      "1339 / 1583\n",
      "1340 / 1583\n",
      "1341 / 1583\n",
      "1342 / 1583\n",
      "1343 / 1583\n",
      "1344 / 1583\n",
      "1345 / 1583\n",
      "1346 / 1583\n",
      "1347 / 1583\n",
      "1348 / 1583\n",
      "1349 / 1583\n",
      "1350 / 1583\n",
      "1351 / 1583\n",
      "1352 / 1583\n",
      "1353 / 1583\n",
      "1354 / 1583\n",
      "1355 / 1583\n",
      "1356 / 1583\n",
      "1357 / 1583\n",
      "1358 / 1583\n",
      "1359 / 1583\n",
      "1360 / 1583\n",
      "1361 / 1583\n",
      "1362 / 1583\n",
      "1363 / 1583\n",
      "1364 / 1583\n",
      "1365 / 1583\n",
      "1366 / 1583\n",
      "1367 / 1583\n",
      "1368 / 1583\n",
      "1369 / 1583\n",
      "1370 / 1583\n",
      "1371 / 1583\n",
      "1372 / 1583\n",
      "1373 / 1583\n",
      "1374 / 1583\n",
      "1375 / 1583\n",
      "1376 / 1583\n",
      "1377 / 1583\n",
      "1378 / 1583\n",
      "1379 / 1583\n",
      "1380 / 1583\n",
      "1381 / 1583\n",
      "1382 / 1583\n",
      "1383 / 1583\n",
      "1384 / 1583\n",
      "1385 / 1583\n",
      "1386 / 1583\n",
      "1387 / 1583\n",
      "1388 / 1583\n",
      "1389 / 1583\n",
      "1390 / 1583\n",
      "1391 / 1583\n",
      "1392 / 1583\n",
      "1393 / 1583\n",
      "1394 / 1583\n",
      "1395 / 1583\n",
      "1396 / 1583\n",
      "1397 / 1583\n",
      "1398 / 1583\n",
      "1399 / 1583\n",
      "1400 / 1583\n",
      "1401 / 1583\n",
      "1402 / 1583\n",
      "1403 / 1583\n",
      "1404 / 1583\n",
      "1405 / 1583\n",
      "1406 / 1583\n",
      "1407 / 1583\n",
      "1408 / 1583\n",
      "1409 / 1583\n",
      "1410 / 1583\n",
      "1411 / 1583\n",
      "1412 / 1583\n",
      "1413 / 1583\n",
      "1414 / 1583\n",
      "1415 / 1583\n",
      "1416 / 1583\n",
      "1417 / 1583\n",
      "1418 / 1583\n",
      "1419 / 1583\n",
      "1420 / 1583\n",
      "1421 / 1583\n",
      "1422 / 1583\n",
      "1423 / 1583\n",
      "1424 / 1583\n",
      "1425 / 1583\n",
      "1426 / 1583\n",
      "1427 / 1583\n",
      "1428 / 1583\n",
      "1429 / 1583\n",
      "1430 / 1583\n",
      "1431 / 1583\n",
      "1432 / 1583\n",
      "1433 / 1583\n",
      "1434 / 1583\n",
      "1435 / 1583\n",
      "1436 / 1583\n",
      "1437 / 1583\n",
      "1438 / 1583\n",
      "1439 / 1583\n",
      "1440 / 1583\n",
      "1441 / 1583\n",
      "1442 / 1583\n",
      "1443 / 1583\n",
      "1444 / 1583\n",
      "1445 / 1583\n",
      "1446 / 1583\n",
      "1447 / 1583\n",
      "1448 / 1583\n",
      "1449 / 1583\n",
      "1450 / 1583\n",
      "1451 / 1583\n",
      "1452 / 1583\n",
      "1453 / 1583\n",
      "1454 / 1583\n",
      "1455 / 1583\n",
      "1456 / 1583\n",
      "1457 / 1583\n",
      "1458 / 1583\n",
      "1459 / 1583\n",
      "1460 / 1583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1461 / 1583\n",
      "1462 / 1583\n",
      "1463 / 1583\n",
      "1464 / 1583\n",
      "1465 / 1583\n",
      "1466 / 1583\n",
      "1467 / 1583\n",
      "1468 / 1583\n",
      "1469 / 1583\n",
      "1470 / 1583\n",
      "1471 / 1583\n",
      "1472 / 1583\n",
      "1473 / 1583\n",
      "1474 / 1583\n",
      "1475 / 1583\n",
      "1476 / 1583\n",
      "1477 / 1583\n",
      "1478 / 1583\n",
      "1479 / 1583\n",
      "1480 / 1583\n",
      "1481 / 1583\n",
      "1482 / 1583\n",
      "1483 / 1583\n",
      "1484 / 1583\n",
      "1485 / 1583\n",
      "1486 / 1583\n",
      "1487 / 1583\n",
      "1488 / 1583\n",
      "1489 / 1583\n",
      "1490 / 1583\n",
      "1491 / 1583\n",
      "1492 / 1583\n",
      "1493 / 1583\n",
      "1494 / 1583\n",
      "1495 / 1583\n",
      "1496 / 1583\n",
      "1497 / 1583\n",
      "1498 / 1583\n",
      "1499 / 1583\n",
      "1500 / 1583\n",
      "1501 / 1583\n",
      "1502 / 1583\n",
      "1503 / 1583\n",
      "1504 / 1583\n",
      "1505 / 1583\n",
      "1506 / 1583\n",
      "1507 / 1583\n",
      "1508 / 1583\n",
      "1509 / 1583\n",
      "1510 / 1583\n",
      "1511 / 1583\n",
      "1512 / 1583\n",
      "1513 / 1583\n",
      "1514 / 1583\n",
      "1515 / 1583\n",
      "1516 / 1583\n",
      "1517 / 1583\n",
      "1518 / 1583\n",
      "1519 / 1583\n",
      "1520 / 1583\n",
      "1521 / 1583\n",
      "1522 / 1583\n",
      "1523 / 1583\n",
      "1524 / 1583\n",
      "1525 / 1583\n",
      "1526 / 1583\n",
      "1527 / 1583\n",
      "1528 / 1583\n",
      "1529 / 1583\n",
      "1530 / 1583\n",
      "1531 / 1583\n",
      "1532 / 1583\n",
      "1533 / 1583\n",
      "1534 / 1583\n",
      "1535 / 1583\n",
      "1536 / 1583\n",
      "1537 / 1583\n",
      "1538 / 1583\n",
      "1539 / 1583\n",
      "1540 / 1583\n",
      "1541 / 1583\n",
      "1542 / 1583\n",
      "1543 / 1583\n",
      "1544 / 1583\n",
      "1545 / 1583\n",
      "1546 / 1583\n",
      "1547 / 1583\n",
      "1548 / 1583\n",
      "1549 / 1583\n",
      "1550 / 1583\n",
      "1551 / 1583\n",
      "1552 / 1583\n",
      "1553 / 1583\n",
      "1554 / 1583\n",
      "1555 / 1583\n",
      "1556 / 1583\n",
      "1557 / 1583\n",
      "1558 / 1583\n",
      "1559 / 1583\n",
      "1560 / 1583\n",
      "1561 / 1583\n",
      "1562 / 1583\n",
      "1563 / 1583\n",
      "1564 / 1583\n",
      "1565 / 1583\n",
      "1566 / 1583\n",
      "1567 / 1583\n",
      "1568 / 1583\n",
      "1569 / 1583\n",
      "1570 / 1583\n",
      "1571 / 1583\n",
      "1572 / 1583\n",
      "1573 / 1583\n",
      "1574 / 1583\n",
      "1575 / 1583\n",
      "1576 / 1583\n",
      "1577 / 1583\n",
      "1578 / 1583\n",
      "1579 / 1583\n",
      "1580 / 1583\n",
      "1581 / 1583\n",
      "1582 / 1583\n",
      "Results saved to: output_data/enron_bert_testing_cosine.csv\n"
     ]
    }
   ],
   "source": [
    "# test model on same train data\n",
    "test_nn(embeddings_file_path = os.path.join(\"input_data\", \"enron_embeddings.csv\"), \n",
    "        distance_type=\"cosine\",\n",
    "       file_prefix=\"enron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doc2vec_similarity import train_doc2vec, test_doc2vec, predict_doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/24/2019 14:44:07 - WARNING - gensim.models.base_any2vec -   consider setting layer size to a multiple of 4 for greater performance\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.doc2vec -   collecting all words and their counts\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.doc2vec -   PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.doc2vec -   collected 16557 word types and 1583 unique tags from a corpus of 1583 examples and 618667 words\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.word2vec -   Loading a fresh vocabulary\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.word2vec -   effective_min_count=2 retains 12011 unique words (72% of original 16557, drops 4546)\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.word2vec -   effective_min_count=2 leaves 614121 word corpus (99% of original 618667, drops 4546)\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.word2vec -   deleting the raw counts dictionary of 16557 items\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.word2vec -   sample=0.001 downsamples 48 most-common words\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.word2vec -   downsampling leaves estimated 525580 word corpus (85.6% of prior 614121)\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.base_any2vec -   estimated required memory for 12011 words and 50 dimensions: 11443100 bytes\n",
      "12/24/2019 14:44:07 - INFO - gensim.models.word2vec -   resetting layer weights\n",
      "12/24/2019 14:44:09 - INFO - gensim.models.base_any2vec -   training model with 3 workers on 12011 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "12/24/2019 14:44:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:10 - INFO - gensim.models.base_any2vec -   EPOCH - 1 : training on 618667 raw words (491577 effective words) took 0.4s, 1344720 effective words/s\n",
      "12/24/2019 14:44:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:10 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:10 - INFO - gensim.models.base_any2vec -   EPOCH - 2 : training on 618667 raw words (491183 effective words) took 0.4s, 1334846 effective words/s\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   EPOCH - 3 : training on 618667 raw words (491567 effective words) took 0.4s, 1342232 effective words/s\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   EPOCH - 4 : training on 618667 raw words (491651 effective words) took 0.4s, 1292757 effective words/s\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:11 - INFO - gensim.models.base_any2vec -   EPOCH - 5 : training on 618667 raw words (491196 effective words) took 0.4s, 1314913 effective words/s\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   EPOCH - 6 : training on 618667 raw words (491415 effective words) took 0.4s, 1275005 effective words/s\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   EPOCH - 7 : training on 618667 raw words (491192 effective words) took 0.4s, 1312335 effective words/s\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:12 - INFO - gensim.models.base_any2vec -   EPOCH - 8 : training on 618667 raw words (491442 effective words) took 0.4s, 1336342 effective words/s\n",
      "12/24/2019 14:44:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:13 - INFO - gensim.models.base_any2vec -   EPOCH - 9 : training on 618667 raw words (491523 effective words) took 0.4s, 1309883 effective words/s\n",
      "12/24/2019 14:44:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:13 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:13 - INFO - gensim.models.base_any2vec -   EPOCH - 10 : training on 618667 raw words (491414 effective words) took 0.4s, 1335318 effective words/s\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   EPOCH - 11 : training on 618667 raw words (491684 effective words) took 0.4s, 1315353 effective words/s\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   EPOCH - 12 : training on 618667 raw words (491377 effective words) took 0.4s, 1320241 effective words/s\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:14 - INFO - gensim.models.base_any2vec -   EPOCH - 13 : training on 618667 raw words (491177 effective words) took 0.4s, 1231999 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/24/2019 14:44:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:15 - INFO - gensim.models.base_any2vec -   EPOCH - 14 : training on 618667 raw words (491587 effective words) took 0.4s, 1240003 effective words/s\n",
      "12/24/2019 14:44:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:15 - INFO - gensim.models.base_any2vec -   EPOCH - 15 : training on 618667 raw words (491479 effective words) took 0.4s, 1245428 effective words/s\n",
      "12/24/2019 14:44:15 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   EPOCH - 16 : training on 618667 raw words (491224 effective words) took 0.4s, 1233147 effective words/s\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   EPOCH - 17 : training on 618667 raw words (491242 effective words) took 0.4s, 1233650 effective words/s\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:16 - INFO - gensim.models.base_any2vec -   EPOCH - 18 : training on 618667 raw words (491170 effective words) took 0.4s, 1214429 effective words/s\n",
      "12/24/2019 14:44:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:17 - INFO - gensim.models.base_any2vec -   EPOCH - 19 : training on 618667 raw words (491368 effective words) took 0.4s, 1206382 effective words/s\n",
      "12/24/2019 14:44:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:17 - INFO - gensim.models.base_any2vec -   EPOCH - 20 : training on 618667 raw words (491351 effective words) took 0.4s, 1260611 effective words/s\n",
      "12/24/2019 14:44:17 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   EPOCH - 21 : training on 618667 raw words (490917 effective words) took 0.4s, 1269774 effective words/s\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   EPOCH - 22 : training on 618667 raw words (491500 effective words) took 0.4s, 1194569 effective words/s\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:18 - INFO - gensim.models.base_any2vec -   EPOCH - 23 : training on 618667 raw words (491396 effective words) took 0.4s, 1174337 effective words/s\n",
      "12/24/2019 14:44:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:19 - INFO - gensim.models.base_any2vec -   EPOCH - 24 : training on 618667 raw words (491610 effective words) took 0.4s, 1170931 effective words/s\n",
      "12/24/2019 14:44:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:19 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:19 - INFO - gensim.models.base_any2vec -   EPOCH - 25 : training on 618667 raw words (491307 effective words) took 0.4s, 1177430 effective words/s\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   EPOCH - 26 : training on 618667 raw words (491426 effective words) took 0.4s, 1246138 effective words/s\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   EPOCH - 27 : training on 618667 raw words (491375 effective words) took 0.4s, 1259922 effective words/s\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:20 - INFO - gensim.models.base_any2vec -   EPOCH - 28 : training on 618667 raw words (491263 effective words) took 0.4s, 1291199 effective words/s\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   EPOCH - 29 : training on 618667 raw words (491261 effective words) took 0.4s, 1331613 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   EPOCH - 30 : training on 618667 raw words (491169 effective words) took 0.4s, 1339985 effective words/s\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:21 - INFO - gensim.models.base_any2vec -   EPOCH - 31 : training on 618667 raw words (491501 effective words) took 0.4s, 1336126 effective words/s\n",
      "12/24/2019 14:44:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:22 - INFO - gensim.models.base_any2vec -   EPOCH - 32 : training on 618667 raw words (491090 effective words) took 0.4s, 1341760 effective words/s\n",
      "12/24/2019 14:44:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:22 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:22 - INFO - gensim.models.base_any2vec -   EPOCH - 33 : training on 618667 raw words (491510 effective words) took 0.4s, 1376441 effective words/s\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   EPOCH - 34 : training on 618667 raw words (491556 effective words) took 0.4s, 1378975 effective words/s\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   EPOCH - 35 : training on 618667 raw words (491307 effective words) took 0.4s, 1382008 effective words/s\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:23 - INFO - gensim.models.base_any2vec -   EPOCH - 36 : training on 618667 raw words (491314 effective words) took 0.4s, 1382856 effective words/s\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   EPOCH - 37 : training on 618667 raw words (491338 effective words) took 0.4s, 1370189 effective words/s\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   EPOCH - 38 : training on 618667 raw words (491524 effective words) took 0.4s, 1361202 effective words/s\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:24 - INFO - gensim.models.base_any2vec -   EPOCH - 39 : training on 618667 raw words (491252 effective words) took 0.4s, 1199163 effective words/s\n",
      "12/24/2019 14:44:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 2 more threads\n",
      "12/24/2019 14:44:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 1 more threads\n",
      "12/24/2019 14:44:25 - INFO - gensim.models.base_any2vec -   worker thread finished; awaiting finish of 0 more threads\n",
      "12/24/2019 14:44:25 - INFO - gensim.models.base_any2vec -   EPOCH - 40 : training on 618667 raw words (491321 effective words) took 0.4s, 1274644 effective words/s\n",
      "12/24/2019 14:44:25 - INFO - gensim.models.base_any2vec -   training on a 24746680 raw words (19654756 effective words) took 15.4s, 1277806 effective words/s\n",
      "12/24/2019 14:44:25 - INFO - gensim.utils -   saving Doc2Vec object under input_data/enron_doc2vec_model.bin, separately None\n",
      "12/24/2019 14:44:25 - INFO - gensim.utils -   saved input_data/enron_doc2vec_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: input_data/enron_doc2vec_model.bin\n"
     ]
    }
   ],
   "source": [
    "train_doc2vec(model_file_name = os.path.join(\"input_data\", \"enron_doc2vec_model.bin\"), \n",
    "              embeddings_file_path = os.path.join(\"input_data\", \"enron_embeddings.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/24/2019 14:44:26 - INFO - gensim.utils -   loading Doc2Vec object from input_data/enron_doc2vec_model.bin\n",
      "12/24/2019 14:44:26 - INFO - gensim.utils -   loading vocabulary recursively from input_data/enron_doc2vec_model.bin.vocabulary.* with mmap=None\n",
      "12/24/2019 14:44:26 - INFO - gensim.utils -   loading trainables recursively from input_data/enron_doc2vec_model.bin.trainables.* with mmap=None\n",
      "12/24/2019 14:44:26 - INFO - gensim.utils -   loading wv recursively from input_data/enron_doc2vec_model.bin.wv.* with mmap=None\n",
      "12/24/2019 14:44:26 - INFO - gensim.utils -   loading docvecs recursively from input_data/enron_doc2vec_model.bin.docvecs.* with mmap=None\n",
      "12/24/2019 14:44:26 - INFO - gensim.utils -   loaded input_data/enron_doc2vec_model.bin\n",
      "12/24/2019 14:44:26 - INFO - gensim.models.keyedvectors -   precomputing L2-norms of doc weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: input_data/enron_doc2vec_model.bin\n"
     ]
    }
   ],
   "source": [
    "test_doc2vec(embeddings_file_path = os.path.join(\"input_data\", \"enron_embeddings.csv\"), \n",
    "             model_file_name = os.path.join(\"input_data\", \"enron_doc2vec_model.bin\"),\n",
    "             results_path = os.path.join(\"output_data\", \"enron_doc2vec_testing.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from precision_recall import p_r_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Name:  bert_manhattan\n",
      "Precision:  bert_manhattan 1.0\n",
      "Recall:  bert_manhattan 1.0\n",
      "F1 score:  bert_manhattan 1.0\n",
      "\n",
      "Model Name:  bert_cosine\n",
      "Precision:  bert_cosine 1.0\n",
      "Recall:  bert_cosine 1.0\n",
      "F1 score:  bert_cosine 1.0\n",
      "\n",
      "Model Name:  doc2vec\n",
      "Precision:  doc2vec 1.0\n",
      "Recall:  doc2vec 0.2533164876816172\n",
      "F1 score:  doc2vec 0.40423387096774194\n"
     ]
    }
   ],
   "source": [
    "p_r_f1_scores(man_results_path       = os.path.join(\"output_data\", \"enron_bert_testing_manhattan.csv\"),\n",
    "              cos_results_path        = os.path.join(\"output_data\", \"enron_bert_testing_cosine.csv\"),\n",
    "              doc2vec_results_path    = os.path.join(\"output_data\", \"enron_doc2vec_testing.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict closest document to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/24/2019 14:45:13 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/matthewdanielson/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "12/24/2019 14:45:13 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at input_data/bert/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "12/24/2019 14:45:13 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "12/24/2019 14:45:13 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at input_data/bert/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    }
   ],
   "source": [
    "from transformers.tokenization_bert import BertTokenizer\n",
    "from transformers.modeling_bert import BertModel\n",
    "\n",
    "embeddings_file_path = os.path.join(\"input_data\", \"enron_embeddings.csv\")\n",
    "\n",
    "df = pd.read_csv(embeddings_file_path)\n",
    "df[\"embedding\"] = df[\"embedding\"].apply(lambda x: ast.literal_eval(re.sub(\"\\s+\", \", \", re.sub(\"\\[\\s+\", \"[\", x))))\n",
    "\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # # Loading pre-trained model (weights)\n",
    "    # # and putting the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model = BertModel.from_pretrained('bert-base-uncased', cache_dir=os.path.join(\"input_data\", \"bert\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"2 of our counterparties are writing letters of complaint.. here's a sample of some of the quotes we have heard from the 10 counterparties we have added in the last 6 months.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'distance': 64.32,\n",
       "  'doc_index': 745,\n",
       "  'text': 'Good morning - these are the levels we will be following today in US,\\n TY,FV, E$, SP:\\t\\t\\t\\t\\t\\t\\n \\t\\tUSH2\\tTYH2\\tFVH2\\tEDM2\\tSPH2\\n target\\t\\t101-26\\t105-05\\t105-19+\\t97.64\\t1157.30\\n target\\t\\t101-09\\t104-24\\t105-12\\t97.60\\t1153.20\\n target\\t\\t100-30\\t104-15\\t105-06\\t97.55\\t1149.10\\n pivot\\t\\t100-24\\t104-12+\\t105-04+\\t97.56\\t1147.40\\n pivot\\t\\t100-14\\t104-04\\t105-00\\t97.52\\t1146.60\\n target\\t\\t100-05\\t103-31+\\t104-28\\t97.50\\t1142.60\\n target\\t\\t99-29\\t103-22+\\t104-23+\\t97.47\\t1140.90\\n target\\t\\t99-20\\t103-17+\\t104-18+\\t97.42\\t1135.00\\n next\\t\\t12/27\\t\\t\\t12/28\\t12/28\\n cycle\\t\\t\\t\\t\\t\\t\\n Good Luck Today\\n Jon and Warren at the CBOT \\n 312-987-5970 or 800-547-3587, 312-347-5061\\n This report has been prepared for informational purposes only. It does not\\n constitute an offer, recommendation or solicitation to buy or sell any\\n securities. It is based on information generally available to the public\\n from sources believed to be reliable. No representation is made that the\\n information is accurate or complete or that any returns indicated will be\\n achieved. Past performance is not indicative of future results. Price and\\n availability are subject to change without notice. Additional information\\n is available upon request. \\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'},\n",
       " 2: {'distance': 73.857,\n",
       "  'doc_index': 1021,\n",
       "  'text': 'EB2762 !\\n From: Saji John@ENRON COMMUNICATIONS on 02/07/2001 11:08 AM\\n To: Harry Arora/HOU/ECT@ECT@ENRON\\n cc: Steve Crumley/Enron Communications@Enron Communications \\n Subject: Re: Meeting on RSL Capacity Auctions  \\n Harry,\\n We do not have any conference room available between 2:00 and 3:00PM. Can we \\n meet at your office during that time ?\\n Thanks\\n Saji John\\n \\tHarry Arora@ECT\\n \\t02/07/01 10:50 AM\\n \\t\\t To: Saji John/Enron Communications@ENRON COMMUNICATIONS@ENRON\\n \\t\\t cc: \\n \\t\\t Subject: Re: Meeting on RSL Capacity Auctions\\n That sounds good.\\n Harry\\n From: Saji John@ENRON COMMUNICATIONS on 02/07/2001 10:39 AM\\n To: Harry Arora/HOU/ECT@ECT\\n cc:  \\n Subject: Meeting on RSL Capacity Auctions\\n Harry,\\n How about meeting today between 2:00PM and 3:00PM.\\n Thanks\\n Saji John\\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'},\n",
       " 3: {'distance': 73.857,\n",
       "  'doc_index': 830,\n",
       "  'text': 'EB2762 !\\n From: Saji John@ENRON COMMUNICATIONS on 02/07/2001 11:08 AM\\n To: Harry Arora/HOU/ECT@ECT@ENRON\\n cc: Steve Crumley/Enron Communications@Enron Communications \\n Subject: Re: Meeting on RSL Capacity Auctions  \\n Harry,\\n We do not have any conference room available between 2:00 and 3:00PM. Can we \\n meet at your office during that time ?\\n Thanks\\n Saji John\\n \\tHarry Arora@ECT\\n \\t02/07/01 10:50 AM\\n \\t\\t To: Saji John/Enron Communications@ENRON COMMUNICATIONS@ENRON\\n \\t\\t cc: \\n \\t\\t Subject: Re: Meeting on RSL Capacity Auctions\\n That sounds good.\\n Harry\\n From: Saji John@ENRON COMMUNICATIONS on 02/07/2001 10:39 AM\\n To: Harry Arora/HOU/ECT@ECT\\n cc:  \\n Subject: Meeting on RSL Capacity Auctions\\n Harry,\\n How about meeting today between 2:00PM and 3:00PM.\\n Thanks\\n Saji John\\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'},\n",
       " 4: {'distance': 75.875,\n",
       "  'doc_index': 169,\n",
       "  'text': 'Dear Mr. Arora:\\n Once again, thank you for the great opportunity to demonstrate and prove my\\n credentials, interest and desire to work for Enron this summer during the\\n second round of on-campus interview at the Owen Graduate School of\\n Management at Vanderbilt University on January 24th. Although I have not\\n been selected for the Summer Associate position at Enron, I would like to\\n assure you that I am still interested in a full-time position at Enron upon\\n my graduation.\\n Meanwhile, I would greatly appreciate if you provide me with any feedback on\\n my performance during the interview. I am especially interested in your\\n opinion regarding the areas I need to improve.\\n Again, thank you for your time and consideration.\\n Sincerely,\\n Dmitri Villevald\\n Owen MBA 2002\\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'},\n",
       " 5: {'distance': 75.875,\n",
       "  'doc_index': 166,\n",
       "  'text': 'Dear Mr. Arora:\\n Once again, thank you for the great opportunity to demonstrate and prove my\\n credentials, interest and desire to work for Enron this summer during the\\n second round of on-campus interview at the Owen Graduate School of\\n Management at Vanderbilt University on January 24th. Although I have not\\n been selected for the Summer Associate position at Enron, I would like to\\n assure you that I am still interested in a full-time position at Enron upon\\n my graduation.\\n Meanwhile, I would greatly appreciate if you provide me with any feedback on\\n my performance during the interview. I am especially interested in your\\n opinion regarding the areas I need to improve.\\n Again, thank you for your time and consideration.\\n Sincerely,\\n Dmitri Villevald\\n Owen MBA 2002\\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_nn(document, df, tokenizer, model, closest_docs_threshold=5, distance_type=\"manhattan\", file_prefix =\"enron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'distance': 0.021,\n",
       "  'doc_index': 745,\n",
       "  'text': 'Good morning - these are the levels we will be following today in US,\\n TY,FV, E$, SP:\\t\\t\\t\\t\\t\\t\\n \\t\\tUSH2\\tTYH2\\tFVH2\\tEDM2\\tSPH2\\n target\\t\\t101-26\\t105-05\\t105-19+\\t97.64\\t1157.30\\n target\\t\\t101-09\\t104-24\\t105-12\\t97.60\\t1153.20\\n target\\t\\t100-30\\t104-15\\t105-06\\t97.55\\t1149.10\\n pivot\\t\\t100-24\\t104-12+\\t105-04+\\t97.56\\t1147.40\\n pivot\\t\\t100-14\\t104-04\\t105-00\\t97.52\\t1146.60\\n target\\t\\t100-05\\t103-31+\\t104-28\\t97.50\\t1142.60\\n target\\t\\t99-29\\t103-22+\\t104-23+\\t97.47\\t1140.90\\n target\\t\\t99-20\\t103-17+\\t104-18+\\t97.42\\t1135.00\\n next\\t\\t12/27\\t\\t\\t12/28\\t12/28\\n cycle\\t\\t\\t\\t\\t\\t\\n Good Luck Today\\n Jon and Warren at the CBOT \\n 312-987-5970 or 800-547-3587, 312-347-5061\\n This report has been prepared for informational purposes only. It does not\\n constitute an offer, recommendation or solicitation to buy or sell any\\n securities. It is based on information generally available to the public\\n from sources believed to be reliable. No representation is made that the\\n information is accurate or complete or that any returns indicated will be\\n achieved. Past performance is not indicative of future results. Price and\\n availability are subject to change without notice. Additional information\\n is available upon request. \\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'},\n",
       " 2: {'distance': 0.022,\n",
       "  'doc_index': 830,\n",
       "  'text': 'EB2762 !\\n From: Saji John@ENRON COMMUNICATIONS on 02/07/2001 11:08 AM\\n To: Harry Arora/HOU/ECT@ECT@ENRON\\n cc: Steve Crumley/Enron Communications@Enron Communications \\n Subject: Re: Meeting on RSL Capacity Auctions  \\n Harry,\\n We do not have any conference room available between 2:00 and 3:00PM. Can we \\n meet at your office during that time ?\\n Thanks\\n Saji John\\n \\tHarry Arora@ECT\\n \\t02/07/01 10:50 AM\\n \\t\\t To: Saji John/Enron Communications@ENRON COMMUNICATIONS@ENRON\\n \\t\\t cc: \\n \\t\\t Subject: Re: Meeting on RSL Capacity Auctions\\n That sounds good.\\n Harry\\n From: Saji John@ENRON COMMUNICATIONS on 02/07/2001 10:39 AM\\n To: Harry Arora/HOU/ECT@ECT\\n cc:  \\n Subject: Meeting on RSL Capacity Auctions\\n Harry,\\n How about meeting today between 2:00PM and 3:00PM.\\n Thanks\\n Saji John\\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'},\n",
       " 3: {'distance': 0.022,\n",
       "  'doc_index': 1021,\n",
       "  'text': 'EB2762 !\\n From: Saji John@ENRON COMMUNICATIONS on 02/07/2001 11:08 AM\\n To: Harry Arora/HOU/ECT@ECT@ENRON\\n cc: Steve Crumley/Enron Communications@Enron Communications \\n Subject: Re: Meeting on RSL Capacity Auctions  \\n Harry,\\n We do not have any conference room available between 2:00 and 3:00PM. Can we \\n meet at your office during that time ?\\n Thanks\\n Saji John\\n \\tHarry Arora@ECT\\n \\t02/07/01 10:50 AM\\n \\t\\t To: Saji John/Enron Communications@ENRON COMMUNICATIONS@ENRON\\n \\t\\t cc: \\n \\t\\t Subject: Re: Meeting on RSL Capacity Auctions\\n That sounds good.\\n Harry\\n From: Saji John@ENRON COMMUNICATIONS on 02/07/2001 10:39 AM\\n To: Harry Arora/HOU/ECT@ECT\\n cc:  \\n Subject: Meeting on RSL Capacity Auctions\\n Harry,\\n How about meeting today between 2:00PM and 3:00PM.\\n Thanks\\n Saji John\\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'},\n",
       " 4: {'distance': 0.027,\n",
       "  'doc_index': 169,\n",
       "  'text': 'Dear Mr. Arora:\\n Once again, thank you for the great opportunity to demonstrate and prove my\\n credentials, interest and desire to work for Enron this summer during the\\n second round of on-campus interview at the Owen Graduate School of\\n Management at Vanderbilt University on January 24th. Although I have not\\n been selected for the Summer Associate position at Enron, I would like to\\n assure you that I am still interested in a full-time position at Enron upon\\n my graduation.\\n Meanwhile, I would greatly appreciate if you provide me with any feedback on\\n my performance during the interview. I am especially interested in your\\n opinion regarding the areas I need to improve.\\n Again, thank you for your time and consideration.\\n Sincerely,\\n Dmitri Villevald\\n Owen MBA 2002\\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'},\n",
       " 5: {'distance': 0.027,\n",
       "  'doc_index': 1534,\n",
       "  'text': 'Dear Mr. Arora:\\n Once again, thank you for the great opportunity to demonstrate and prove my\\n credentials, interest and desire to work for Enron this summer during the\\n second round of on-campus interview at the Owen Graduate School of\\n Management at Vanderbilt University on January 24th. Although I have not\\n been selected for the Summer Associate position at Enron, I would like to\\n assure you that I am still interested in a full-time position at Enron upon\\n my graduation.\\n Meanwhile, I would greatly appreciate if you provide me with any feedback on\\n my performance during the interview. I am especially interested in your\\n opinion regarding the areas I need to improve.\\n Again, thank you for your time and consideration.\\n Sincerely,\\n Dmitri Villevald\\n Owen MBA 2002\\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'},\n",
       " 6: {'distance': 0.027,\n",
       "  'doc_index': 166,\n",
       "  'text': 'Dear Mr. Arora:\\n Once again, thank you for the great opportunity to demonstrate and prove my\\n credentials, interest and desire to work for Enron this summer during the\\n second round of on-campus interview at the Owen Graduate School of\\n Management at Vanderbilt University on January 24th. Although I have not\\n been selected for the Summer Associate position at Enron, I would like to\\n assure you that I am still interested in a full-time position at Enron upon\\n my graduation.\\n Meanwhile, I would greatly appreciate if you provide me with any feedback on\\n my performance during the interview. I am especially interested in your\\n opinion regarding the areas I need to improve.\\n Again, thank you for your time and consideration.\\n Sincerely,\\n Dmitri Villevald\\n Owen MBA 2002\\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'},\n",
       " 7: {'distance': 0.027,\n",
       "  'doc_index': 1339,\n",
       "  'text': 'Dear Mr. Arora:\\n Once again, thank you for the great opportunity to demonstrate and prove my\\n credentials, interest and desire to work for Enron this summer during the\\n second round of on-campus interview at the Owen Graduate School of\\n Management at Vanderbilt University on January 24th. Although I have not\\n been selected for the Summer Associate position at Enron, I would like to\\n assure you that I am still interested in a full-time position at Enron upon\\n my graduation.\\n Meanwhile, I would greatly appreciate if you provide me with any feedback on\\n my performance during the interview. I am especially interested in your\\n opinion regarding the areas I need to improve.\\n Again, thank you for your time and consideration.\\n Sincerely,\\n Dmitri Villevald\\n Owen MBA 2002\\n EDRM Enron Email Data Set has been produced in EML, PST and NSF format by ZL Technologies, Inc. This Data Set is licensed under a Creative Commons Attribution 3.0 United States License <http://creativecommons.org/licenses/by/3.0/us/> . To provide attribution, please cite to \"ZL Technologies, Inc. (http://www.zlti.com).\"\\n'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_nn(document, df, tokenizer, model, closest_docs_threshold=7, distance_type=\"cosine\", file_prefix =\"enron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/20/2019 18:41:46 - INFO - gensim.utils -   loading Doc2Vec object from input_data/enron_doc2vec_model.bin\n",
      "12/20/2019 18:41:46 - INFO - gensim.utils -   loading vocabulary recursively from input_data/enron_doc2vec_model.bin.vocabulary.* with mmap=None\n",
      "12/20/2019 18:41:46 - INFO - gensim.utils -   loading trainables recursively from input_data/enron_doc2vec_model.bin.trainables.* with mmap=None\n",
      "12/20/2019 18:41:46 - INFO - gensim.utils -   loading wv recursively from input_data/enron_doc2vec_model.bin.wv.* with mmap=None\n",
      "12/20/2019 18:41:46 - INFO - gensim.utils -   loading docvecs recursively from input_data/enron_doc2vec_model.bin.docvecs.* with mmap=None\n",
      "12/20/2019 18:41:46 - INFO - gensim.utils -   loaded input_data/enron_doc2vec_model.bin\n",
      "12/20/2019 18:41:46 - INFO - gensim.models.keyedvectors -   precomputing L2-norms of doc weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('enron003_01042.txt', 0.6864506006240845), ('enron003_01250.txt', 0.6756713390350342), ('enron003_01550.txt', 0.6753413677215576), ('enron003_00527.txt', 0.6725666522979736)]\n"
     ]
    }
   ],
   "source": [
    "print(predict_doc2vec(document, model_file_name = os.path.join(\"input_data\", \"enron_doc2vec_model.bin\"), closest_docs_threshold = 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "274px",
    "width": "414px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
